use wasm_bindgen::prelude::*;
use std::collections::HashMap;
use js_sys;

mod renderer;

pub use renderer::{render_ascii_model, Model3D, Vector3};

// ============================================================================
// Core Genetics Functions - HOT PATH optimizations
// ============================================================================

/// Standard DNA codon table (Translation Table 1)
/// Maps 64 codons to their amino acid single-letter codes.
fn codon_to_aa(b0: u8, b1: u8, b2: u8) -> u8 {
    // Encode codon as 6-bit index: (base0 << 4) | (base1 << 2) | base2
    // where A=0, C=1, G=2, T=3
    let encode_base = |b: u8| -> Option<u8> {
        match b {
            b'A' | b'a' => Some(0),
            b'C' | b'c' => Some(1),
            b'G' | b'g' => Some(2),
            b'T' | b't' | b'U' | b'u' => Some(3),
            _ => None, // N or other ambiguous
        }
    };

    let (e0, e1, e2) = match (encode_base(b0), encode_base(b1), encode_base(b2)) {
        (Some(a), Some(b), Some(c)) => (a, b, c),
        _ => return b'X', // Unknown codon
    };

    let idx = ((e0 as usize) << 4) | ((e1 as usize) << 2) | (e2 as usize);

    // Precomputed codon table: index = (base0*16 + base1*4 + base2)
    // Order: AAA, AAC, AAG, AAT, ACA, ACC, ACG, ACT, ...
    const TABLE: &[u8; 64] = b"KNKNTTTTRSRSIIMIQHQHPPPPRRRRLLLLEDEDAAAAGGGGVVVV*Y*YSSSS*CWCLFLF";
    TABLE[idx]
}

/// Translate DNA sequence to amino acid sequence.
///
/// # Arguments
/// * `seq` - DNA sequence string
/// * `frame` - Reading frame (0, 1, or 2)
///
/// # Returns
/// Amino acid sequence as a string. Unknown codons (containing N) become 'X'.
#[wasm_bindgen]
pub fn translate_sequence(seq: &str, frame: u8) -> String {
    let bytes = seq.as_bytes();
    let frame = (frame as usize).min(2);

    if bytes.len() < frame + 3 {
        return String::new();
    }

    let num_codons = (bytes.len() - frame) / 3;
    let mut result = Vec::with_capacity(num_codons);

    let mut i = frame;
    while i + 3 <= bytes.len() {
        let aa = codon_to_aa(bytes[i], bytes[i + 1], bytes[i + 2]);
        result.push(aa);
        i += 3;
    }

    // SAFETY: codon_to_aa only returns ASCII characters
    unsafe { String::from_utf8_unchecked(result) }
}

/// Compute reverse complement of DNA sequence.
///
/// Handles all IUPAC ambiguity codes correctly:
/// - Standard: A<->T, G<->C
/// - Ambiguity: R<->Y, K<->M, S<->S, W<->W, B<->V, D<->H, N<->N
///
/// # Arguments
/// * `seq` - DNA sequence string
///
/// # Returns
/// Reverse complement sequence (preserving case).
#[wasm_bindgen]
pub fn reverse_complement(seq: &str) -> String {
    let bytes = seq.as_bytes();
    let mut result = Vec::with_capacity(bytes.len());

    // Process in reverse
    for &b in bytes.iter().rev() {
        let comp = match b {
            // Standard bases
            b'A' => b'T', b'T' => b'A', b'G' => b'C', b'C' => b'G',
            b'a' => b't', b't' => b'a', b'g' => b'c', b'c' => b'g',
            // IUPAC ambiguity codes
            b'N' => b'N', b'n' => b'n',
            b'R' => b'Y', b'r' => b'y', // Purine (A/G) -> Pyrimidine (T/C)
            b'Y' => b'R', b'y' => b'r',
            b'S' => b'S', b's' => b's', // Strong (G/C)
            b'W' => b'W', b'w' => b'w', // Weak (A/T)
            b'K' => b'M', b'k' => b'm', // Keto (G/T) -> Amino (A/C)
            b'M' => b'K', b'm' => b'k',
            b'B' => b'V', b'b' => b'v', // Not A -> Not T
            b'V' => b'B', b'v' => b'b',
            b'D' => b'H', b'd' => b'h', // Not C -> Not G
            b'H' => b'D', b'h' => b'd',
            // U (RNA) treated as T
            b'U' => b'A', b'u' => b'a',
            // Unknown - keep as is
            other => other,
        };
        result.push(comp);
    }

    // SAFETY: We only transform ASCII characters to ASCII
    unsafe { String::from_utf8_unchecked(result) }
}

/// Calculate GC content percentage.
///
/// Only counts unambiguous A, T, G, C bases. N and other ambiguity codes
/// are excluded from both numerator and denominator.
///
/// # Arguments
/// * `seq` - DNA sequence string
///
/// # Returns
/// GC content as percentage (0-100). Returns 0 if no valid bases.
#[wasm_bindgen]
pub fn calculate_gc_content(seq: &str) -> f64 {
    let bytes = seq.as_bytes();
    let mut gc_count = 0u64;
    let mut total_count = 0u64;

    for &b in bytes {
        match b {
            b'G' | b'g' | b'C' | b'c' => {
                gc_count += 1;
                total_count += 1;
            }
            b'A' | b'a' | b'T' | b't' | b'U' | b'u' => {
                total_count += 1;
            }
            _ => {} // Skip N and other ambiguous bases
        }
    }

    if total_count == 0 {
        0.0
    } else {
        (gc_count as f64 / total_count as f64) * 100.0
    }
}

/// Result of codon usage analysis.
#[wasm_bindgen]
pub struct CodonUsageResult {
    /// JSON-encoded codon counts: { "ATG": 5, "TTT": 12, ... }
    json: String,
}

#[wasm_bindgen]
impl CodonUsageResult {
    /// Get the codon counts as a JSON string.
    #[wasm_bindgen(getter)]
    pub fn json(&self) -> String {
        self.json.clone()
    }
}

/// Count codon usage in a DNA sequence.
///
/// # Arguments
/// * `seq` - DNA sequence string
/// * `frame` - Reading frame (0, 1, or 2)
///
/// # Returns
/// CodonUsageResult with JSON-encoded codon counts.
#[wasm_bindgen]
pub fn count_codon_usage(seq: &str, frame: u8) -> CodonUsageResult {
    let bytes = seq.as_bytes();
    let frame = (frame as usize).min(2);

    let mut counts: HashMap<String, usize> = HashMap::new();

    let mut i = frame;
    while i + 3 <= bytes.len() {
        // Extract codon and uppercase it
        let codon_bytes = &bytes[i..i + 3];
        let codon: String = codon_bytes.iter()
            .map(|&b| (b as char).to_ascii_uppercase())
            .collect();

        *counts.entry(codon).or_insert(0) += 1;
        i += 3;
    }

    // Serialize to JSON
    let json = serde_json_lite_encode(&counts);
    CodonUsageResult { json }
}

/// Simple JSON encoder for HashMap<String, usize>
/// Avoids serde_json dependency for smaller WASM size.
fn serde_json_lite_encode(map: &HashMap<String, usize>) -> String {
    let mut result = String::from("{");
    let mut first = true;

    for (key, value) in map {
        if !first {
            result.push(',');
        }
        first = false;
        result.push('"');
        result.push_str(key);
        result.push_str("\":");
        result.push_str(&value.to_string());
    }

    result.push('}');
    result
}

#[wasm_bindgen]
pub fn init_panic_hook() {
    console_error_panic_hook::set_once();
}

#[wasm_bindgen]
pub fn levenshtein_distance(s1: &str, s2: &str) -> usize {
    let v1: Vec<char> = s1.chars().collect();
    let v2: Vec<char> = s2.chars().collect();
    
    let m = v1.len();
    let n = v2.len();

    if m == 0 { return n; }
    if n == 0 { return m; }

    // Ensure v1 is the shorter string for O(min(M, N)) space
    if m > n {
        return levenshtein_impl(&v2, &v1);
    }
    levenshtein_impl(&v1, &v2)
}

fn levenshtein_impl(s1: &[char], s2: &[char]) -> usize {
    let m = s1.len();
    let mut costs: Vec<usize> = (0..=m).collect();

    for (j, &c2) in s2.iter().enumerate() {
        let mut previous_substitution_cost = costs[0];
        costs[0] = j + 1;

        for (i, &c1) in s1.iter().enumerate() {
            let insertion_cost = costs[i];
            let deletion_cost = costs[i+1];
            
            let substitution_cost = if c1 == c2 {
                previous_substitution_cost
            } else {
                previous_substitution_cost + 1
            };

            previous_substitution_cost = deletion_cost;
            
            costs[i+1] = substitution_cost.min(insertion_cost + 1).min(deletion_cost + 1);
        }
    }

    costs[m]
}

#[wasm_bindgen]
pub struct KmerAnalysisResult {
    pub k: usize,
    pub unique_kmers_a: usize,
    pub unique_kmers_b: usize,
    pub shared_kmers: usize,
    pub jaccard_index: f64,
    pub containment_a_in_b: f64,
    pub containment_b_in_a: f64,
    pub cosine_similarity: f64,
    pub bray_curtis_dissimilarity: f64,
}

fn extract_kmer_freqs(sequence: &str, k: usize) -> HashMap<String, usize> {
    let mut freqs = HashMap::new();
    // Pre-allocate assuming roughly seq_len - k unique kmers
    if sequence.len() < k {
        return freqs;
    }
    
    // Convert to bytes for faster processing. 
    // We assume input is mostly ASCII DNA. Multibyte chars are handled safely by String::from_utf8_lossy if needed,
    // but here we just process bytes and construct Strings for the map keys.
    let seq_bytes = sequence.as_bytes();
    
    // We can iterate windows on bytes.
    // Handling uppercase: we can uppercase the key when inserting.
    
    for i in 0..=(seq_bytes.len() - k) {
        let window = &seq_bytes[i..i+k];
        
        // Check for 'N' or 'n'
        // 'N' is 78, 'n' is 110.
        // Actually, let's just create the string and check.
        // Optimizing this loop is tricky without custom Hasher or encoding.
        // The safest path that is still faster than JS is reducing allocations via strict loops.
        
        // Check for N without allocation
        let has_n = window.iter().any(|&b| b == b'N' || b == b'n');
        if has_n {
            continue;
        }

        // Create String and uppercase
        // from_utf8_lossy returns Cow. 
        // We know it's valid UTF8 if input was valid str.
        let kmer_str = std::str::from_utf8(window).unwrap_or("").to_uppercase();
        
        *freqs.entry(kmer_str).or_insert(0) += 1;
    }
    freqs
}

#[wasm_bindgen]
pub fn analyze_kmers(sequence_a: &str, sequence_b: &str, k: usize) -> KmerAnalysisResult {
    let freqs_a = extract_kmer_freqs(sequence_a, k);
    let freqs_b = extract_kmer_freqs(sequence_b, k);

    let set_a_len = freqs_a.len();
    let set_b_len = freqs_b.len();

    // Iterate over the smaller map for intersection
    let (smaller, larger) = if set_a_len < set_b_len {
        (&freqs_a, &freqs_b)
    } else {
        (&freqs_b, &freqs_a)
    };

    let intersection_count = smaller.keys().filter(|kmer| larger.contains_key(*kmer)).count();
    let union_size = set_a_len + set_b_len - intersection_count;
    
    let jaccard = if union_size > 0 {
        intersection_count as f64 / union_size as f64
    } else {
        1.0
    };

    let containment_a_in_b = if set_a_len > 0 {
        intersection_count as f64 / set_a_len as f64
    } else {
        0.0
    };

    let containment_b_in_a = if set_b_len > 0 {
        intersection_count as f64 / set_b_len as f64
    } else {
        0.0
    };

    // For Cosine/Bray-Curtis, we need to iterate the union.
    // Optimization: iterate keys of A, calculate partials. Iterate keys of B, calculate partials for keys NOT in A.
    // Or just collect union keys.
    
    let mut dot_product = 0.0;
    let mut norm_a = 0.0;
    let mut norm_b = 0.0;
    let mut sum_diff = 0.0;
    let mut sum_total = 0.0;

    // Iterate all keys in A
    for (kmer, &count_a) in &freqs_a {
        let count_a = count_a as f64;
        let count_b = *freqs_b.get(kmer).unwrap_or(&0) as f64;
        
        dot_product += count_a * count_b;
        norm_a += count_a * count_a;
        // norm_b will be calculated fully later? No, we need to sum all B.
        // Let's do it simply to avoid mistakes.
        
        sum_diff += (count_a - count_b).abs();
        sum_total += count_a + count_b;
    }

    // Iterate keys in B that are NOT in A
    for (kmer, &count_b) in &freqs_b {
        if !freqs_a.contains_key(kmer) {
            let count_b = count_b as f64;
            // count_a is 0
            // dot_product += 0 * count_b -> 0
            // norm_a += 0 -> 0
            
            sum_diff += count_b; // abs(0 - count_b)
            sum_total += count_b;
        }
        // Calculate norm_b separately
        norm_b += (count_b as f64).powi(2);
    }

    let cosine_sim = if norm_a > 0.0 && norm_b > 0.0 {
        dot_product / (norm_a.sqrt() * norm_b.sqrt())
    } else {
        0.0
    };

    let bray_curtis = if sum_total > 0.0 {
        sum_diff / sum_total
    } else {
        0.0
    };

    KmerAnalysisResult {
        k,
        unique_kmers_a: set_a_len,
        unique_kmers_b: set_b_len,
        shared_kmers: intersection_count,
        jaccard_index: jaccard,
        containment_a_in_b,
        containment_b_in_a,
        cosine_similarity: cosine_sim,
        bray_curtis_dissimilarity: bray_curtis,
    }
}

#[wasm_bindgen]
pub fn min_hash_jaccard(sequence_a: &str, sequence_b: &str, k: usize, num_hashes: usize) -> f64 {
    // Use the optimized minhash_signature logic (byte-based, rolling hash)
    // This ensures consistency with the rest of the module and handles U/T normalization.
    let sig_a = minhash_signature(sequence_a.as_bytes(), k, num_hashes);
    let sig_b = minhash_signature(sequence_b.as_bytes(), k, num_hashes);

    // Reuse the signature-based Jaccard calculation
    minhash_jaccard_from_signatures(&sig_a.signature, &sig_b.signature)
}

// ============================================================================
// Dense K-mer Counter (bytes-first ABI)
// Optimized for browser-based k-mer analysis with typed array output
// See: docs/WASM_ABI_SPEC.md for conventions
// ============================================================================

/// Maximum k value for dense counting (4^10 = 1,048,576 entries = ~4MB)
const DENSE_KMER_MAX_K: usize = 10;

/// Result of dense k-mer counting.
///
/// # Ownership
/// The caller must call `.free()` to release WASM memory.
#[wasm_bindgen]
pub struct DenseKmerResult {
    /// Dense count array of length 4^k
    counts: Vec<u32>,
    /// Total valid k-mers counted (excludes windows with N)
    total_valid: u64,
    /// K value used
    k: usize,
}

#[wasm_bindgen]
impl DenseKmerResult {
    /// Get the k-mer counts as a Uint32Array.
    /// Length is 4^k where each index represents a k-mer in base-4 encoding:
    /// - A=0, C=1, G=2, T=3
    /// - Index = sum(base[i] * 4^(k-1-i)) for i in 0..k
    ///
    /// Example for k=2: index 0=AA, 1=AC, 2=AG, 3=AT, 4=CA, ... 15=TT
    #[wasm_bindgen(getter)]
    pub fn counts(&self) -> js_sys::Uint32Array {
        let arr = js_sys::Uint32Array::new_with_length(self.counts.len() as u32);
        arr.copy_from(&self.counts);
        arr
    }

    /// Total number of valid k-mers counted (windows without N/ambiguous bases).
    #[wasm_bindgen(getter)]
    pub fn total_valid(&self) -> u64 {
        self.total_valid
    }

    /// K value used for counting.
    #[wasm_bindgen(getter)]
    pub fn k(&self) -> usize {
        self.k
    }

    /// Get the number of unique k-mers (non-zero counts).
    #[wasm_bindgen(getter)]
    pub fn unique_count(&self) -> usize {
        self.counts.iter().filter(|&&c| c > 0).count()
    }
}

/// Error codes for dense k-mer counting.
#[wasm_bindgen]
#[derive(Clone, Copy)]
pub enum DenseKmerError {
    /// K value exceeds safe maximum (currently 10)
    KTooLarge = 1,
    /// K value is zero
    KZero = 2,
    /// Sequence is shorter than k
    SequenceTooShort = 3,
}

/// Dense k-mer counting with typed array output.
///
/// Uses a rolling 2-bit index algorithm with no per-position heap allocations.
/// Ambiguous bases (N and non-ACGT) reset the rolling state.
///
/// # Arguments
/// * `seq` - Sequence as bytes (ASCII). Accepts both upper and lower case.
/// * `k` - K-mer size. Must be 1 <= k <= 10 (4^10 = ~4MB max array).
///
/// # Returns
/// `DenseKmerResult` with:
/// - `counts`: Uint32Array of length 4^k (dense count vector)
/// - `total_valid`: Total valid k-mers counted
/// - `k`: K value used
/// - `unique_count`: Number of unique k-mers observed
///
/// Returns an empty result with all-zero counts if k is invalid.
///
/// # Ownership
/// Caller must call `.free()` when done to release WASM memory.
///
/// # Ambiguous Bases
/// Windows containing non-ACGT bases are skipped. The rolling state resets
/// on any ambiguous base, so no k-mer spans an N.
///
/// # Example (from JS)
/// ```js
/// const result = wasm.count_kmers_dense(sequenceBytes, 6);
/// try {
///   const counts = result.counts; // Uint32Array[4096]
///   const total = result.total_valid;
///   // Use counts...
/// } finally {
///   result.free(); // Required!
/// }
/// ```
///
/// # Determinism
/// Output is fully deterministic. No random number generation.
///
/// @see phage_explorer-vk7b.1.1
/// @see docs/WASM_ABI_SPEC.md
#[wasm_bindgen]
pub fn count_kmers_dense(seq: &[u8], k: usize) -> DenseKmerResult {
    // Validate k
    if k == 0 || k > DENSE_KMER_MAX_K {
        // Return empty result for invalid k
        return DenseKmerResult {
            counts: Vec::new(),
            total_valid: 0,
            k,
        };
    }

    // Calculate array size: 4^k
    let array_size = 1usize << (2 * k); // 4^k = 2^(2k)
    let mut counts = vec![0u32; array_size];

    // Mask for k bases: (4^k - 1) = all 1s in the lower 2k bits
    let mask = array_size - 1;

    // Rolling index state
    let mut rolling_index: usize = 0;
    let mut valid_bases: usize = 0; // How many consecutive valid bases we have
    let mut total_valid: u64 = 0;

    for &byte in seq {
        // Encode base to 2-bit value (A=0, C=1, G=2, T=3)
        let base_code = match byte {
            b'A' | b'a' => 0usize,
            b'C' | b'c' => 1usize,
            b'G' | b'g' => 2usize,
            b'T' | b't' | b'U' | b'u' => 3usize,
            _ => {
                // Ambiguous base - reset rolling state
                rolling_index = 0;
                valid_bases = 0;
                continue;
            }
        };

        // Update rolling index: shift left by 2 bits, add new base, mask to k bases
        rolling_index = ((rolling_index << 2) | base_code) & mask;
        valid_bases += 1;

        // Only count once we have k valid bases
        if valid_bases >= k {
            counts[rolling_index] = counts[rolling_index].saturating_add(1);
            total_valid += 1;
        }
    }

    DenseKmerResult {
        counts,
        total_valid,
        k,
    }
}

/// Dense k-mer counting with reverse complement combined.
///
/// Counts both forward and reverse complement k-mers into the same array.
/// Uses canonical k-mers (min of forward and RC) for strand-independent analysis.
///
/// # Arguments
/// * `seq` - Sequence as bytes (ASCII)
/// * `k` - K-mer size (1 <= k <= 10)
///
/// # Returns
/// `DenseKmerResult` with combined forward + RC counts.
///
/// # Note
/// For odd k values, forward and RC k-mers are always different.
/// For even k values, some palindromic k-mers are their own RC.
#[wasm_bindgen]
pub fn count_kmers_dense_canonical(seq: &[u8], k: usize) -> DenseKmerResult {
    // Validate k
    if k == 0 || k > DENSE_KMER_MAX_K {
        return DenseKmerResult {
            counts: Vec::new(),
            total_valid: 0,
            k,
        };
    }

    let array_size = 1usize << (2 * k);
    let mut counts = vec![0u32; array_size];
    let mask = array_size - 1;

    // We need to track both forward and reverse complement rolling indices
    let mut fwd_index: usize = 0;
    let mut rc_index: usize = 0;
    let mut valid_bases: usize = 0;
    let mut total_valid: u64 = 0;

    // Shift amount for RC: we build RC from the right (LSB)
    let rc_shift = 2 * (k - 1);

    for &byte in seq {
        // Encode base to 2-bit value
        let base_code = match byte {
            b'A' | b'a' => 0usize,
            b'C' | b'c' => 1usize,
            b'G' | b'g' => 2usize,
            b'T' | b't' | b'U' | b'u' => 3usize,
            _ => {
                fwd_index = 0;
                rc_index = 0;
                valid_bases = 0;
                continue;
            }
        };

        // Complement: A<->T (0<->3), C<->G (1<->2)
        let comp_code = 3 - base_code;

        // Forward: shift left, add new base at LSB
        fwd_index = ((fwd_index << 2) | base_code) & mask;

        // RC: shift right, add complement at MSB position
        rc_index = (rc_index >> 2) | (comp_code << rc_shift);

        valid_bases += 1;

        if valid_bases >= k {
            // Use canonical (smaller index) for strand-independent counting
            let canonical = fwd_index.min(rc_index);
            counts[canonical] = counts[canonical].saturating_add(1);
            total_valid += 1;
        }
    }

    DenseKmerResult {
        counts,
        total_valid,
        k,
    }
}

/// Check if a k value is valid for dense k-mer counting.
///
/// Returns true if 1 <= k <= DENSE_KMER_MAX_K (10).
#[wasm_bindgen]
pub fn is_valid_dense_kmer_k(k: usize) -> bool {
    k >= 1 && k <= DENSE_KMER_MAX_K
}

/// Get the maximum allowed k for dense k-mer counting.
#[wasm_bindgen]
pub fn get_dense_kmer_max_k() -> usize {
    DENSE_KMER_MAX_K
}

// ============================================================================
// MinHash Signature (rolling index, typed array output)
// Optimized for fast similarity estimation without string allocations
// See: phage_explorer-vk7b.2.1
// ============================================================================

/// Result of MinHash signature computation.
///
/// # Ownership
/// The caller must call `.free()` to release WASM memory.
#[wasm_bindgen]
pub struct MinHashSignature {
    /// Signature values (minimum hash values for each seed)
    signature: Vec<u32>,
    /// Total valid k-mers processed
    total_kmers: u64,
    /// K value used
    k: usize,
}

#[wasm_bindgen]
impl MinHashSignature {
    /// Get the signature as a Uint32Array.
    /// Length equals num_hashes parameter.
    /// Each element is the minimum hash value for that seed.
    #[wasm_bindgen(getter)]
    pub fn signature(&self) -> js_sys::Uint32Array {
        let arr = js_sys::Uint32Array::new_with_length(self.signature.len() as u32);
        arr.copy_from(&self.signature);
        arr
    }

    /// Total number of valid k-mers hashed.
    #[wasm_bindgen(getter)]
    pub fn total_kmers(&self) -> u64 {
        self.total_kmers
    }

    /// K value used for hashing.
    #[wasm_bindgen(getter)]
    pub fn k(&self) -> usize {
        self.k
    }

    /// Number of hash functions (signature length).
    #[wasm_bindgen(getter)]
    pub fn num_hashes(&self) -> usize {
        self.signature.len()
    }
}

/// Fast 64-bit to 32-bit hash mixing (splitmix-style).
/// Takes a 64-bit k-mer index and a seed, returns a 32-bit hash.
#[inline(always)]
fn mix_hash(index: u64, seed: u32) -> u32 {
    // Combine index with seed
    let mut x = index ^ (seed as u64);
    // Splitmix64-style mixing
    x = x.wrapping_mul(0x9E3779B97F4A7C15);
    x = (x ^ (x >> 30)).wrapping_mul(0xBF58476D1CE4E5B9);
    x = (x ^ (x >> 27)).wrapping_mul(0x94D049BB133111EB);
    x = x ^ (x >> 31);
    // Take lower 32 bits
    x as u32
}

/// Compute MinHash signature using rolling k-mer index.
///
/// Uses a rolling 2-bit index algorithm with no per-k-mer string allocations.
/// Much faster than the string-based approach for long sequences.
///
/// # Arguments
/// * `seq` - Sequence as bytes (ASCII). Case-insensitive, U treated as T.
/// * `k` - K-mer size (no practical limit, uses u64 index)
/// * `num_hashes` - Number of hash functions (signature length)
///
/// # Returns
/// MinHashSignature with `num_hashes` minimum values.
///
/// # Algorithm
/// 1. Maintain rolling 64-bit k-mer index (allows k up to 32)
/// 2. For each valid k-mer, compute hash for each seed
/// 3. Track minimum hash value per seed
/// 4. Ambiguous bases reset rolling state (no k-mer spans N)
#[wasm_bindgen]
pub fn minhash_signature(seq: &[u8], k: usize, num_hashes: usize) -> MinHashSignature {
    // Limit k to 32 for u64 index (4^32 = 2^64)
    let k = k.min(32);

    // Edge cases
    if k == 0 || num_hashes == 0 || seq.len() < k {
        return MinHashSignature {
            signature: vec![u32::MAX; num_hashes],
            total_kmers: 0,
            k,
        };
    }

    let mut signature = vec![u32::MAX; num_hashes];
    let mut total_kmers: u64 = 0;

    // Rolling state
    let mut rolling_index: u64 = 0;
    let mut valid_bases: usize = 0;
    let mask: u64 = if k >= 32 { u64::MAX } else { (1u64 << (2 * k)) - 1 };

    // Pre-compute seeds for each hash function
    let seeds: Vec<u32> = (0..num_hashes)
        .map(|i| (i as u32).wrapping_mul(0x9e3779b9))
        .collect();

    for &byte in seq {
        // Encode base: A=0, C=1, G=2, T/U=3
        let base_code: u64 = match byte {
            b'A' | b'a' => 0,
            b'C' | b'c' => 1,
            b'G' | b'g' => 2,
            b'T' | b't' | b'U' | b'u' => 3,
            _ => {
                // Ambiguous base - reset rolling state
                rolling_index = 0;
                valid_bases = 0;
                continue;
            }
        };

        // Update rolling index: shift left by 2 bits, add new base
        rolling_index = ((rolling_index << 2) | base_code) & mask;
        valid_bases += 1;

        // Once we have k valid bases, we have a valid k-mer
        if valid_bases >= k {
            total_kmers += 1;

            // Compute hash for each seed and update minimum
            for (i, &seed) in seeds.iter().enumerate() {
                let h = mix_hash(rolling_index, seed);
                if h < signature[i] {
                    signature[i] = h;
                }
            }
        }
    }

    MinHashSignature {
        signature,
        total_kmers,
        k,
    }
}

/// Compute MinHash signature using canonical k-mers (strand-independent).
///
/// For each k-mer position, uses the minimum of forward and reverse complement
/// indices before hashing. This makes the signature identical regardless of
/// which strand the sequence represents.
///
/// # Arguments
/// * `seq` - Sequence as bytes (ASCII). Case-insensitive, U treated as T.
/// * `k` - K-mer size (capped at 32 for u64 index)
/// * `num_hashes` - Number of hash functions (signature length)
///
/// # Returns
/// MinHashSignature with strand-independent hashes.
#[wasm_bindgen]
pub fn minhash_signature_canonical(seq: &[u8], k: usize, num_hashes: usize) -> MinHashSignature {
    // Limit k to 32 for u64 index
    let k = k.min(32);

    // Edge cases
    if k == 0 || num_hashes == 0 || seq.len() < k {
        return MinHashSignature {
            signature: vec![u32::MAX; num_hashes],
            total_kmers: 0,
            k,
        };
    }

    let mut signature = vec![u32::MAX; num_hashes];
    let mut total_kmers: u64 = 0;

    // Rolling state for both forward and reverse complement
    let mut fwd_index: u64 = 0;
    let mut rc_index: u64 = 0;
    let mut valid_bases: usize = 0;
    let mask: u64 = if k >= 32 { u64::MAX } else { (1u64 << (2 * k)) - 1 };
    let rc_shift = 2 * (k - 1);

    // Pre-compute seeds
    let seeds: Vec<u32> = (0..num_hashes)
        .map(|i| (i as u32).wrapping_mul(0x9e3779b9))
        .collect();

    for &byte in seq {
        // Encode base: A=0, C=1, G=2, T=3
        let (base_code, comp_code): (u64, u64) = match byte {
            b'A' | b'a' => (0, 3), // A complement is T (3)
            b'C' | b'c' => (1, 2), // C complement is G (2)
            b'G' | b'g' => (2, 1), // G complement is C (1)
            b'T' | b't' | b'U' | b'u' => (3, 0), // T complement is A (0)
            _ => {
                // Ambiguous base - reset
                fwd_index = 0;
                rc_index = 0;
                valid_bases = 0;
                continue;
            }
        };

        // Forward: shift left, add new base at LSB
        fwd_index = ((fwd_index << 2) | base_code) & mask;

        // RC: shift right, add complement at MSB position
        rc_index = (rc_index >> 2) | (comp_code << rc_shift);

        valid_bases += 1;

        if valid_bases >= k {
            total_kmers += 1;

            // Use canonical (smaller) index for strand independence
            let canonical = fwd_index.min(rc_index);

            // Compute hash for each seed
            for (i, &seed) in seeds.iter().enumerate() {
                let h = mix_hash(canonical, seed);
                if h < signature[i] {
                    signature[i] = h;
                }
            }
        }
    }

    MinHashSignature {
        signature,
        total_kmers,
        k,
    }
}

/// Estimate Jaccard similarity between two MinHash signatures.
///
/// # Arguments
/// * `sig_a` - First signature (Uint32Array)
/// * `sig_b` - Second signature (must have same length as sig_a)
///
/// # Returns
/// Estimated Jaccard similarity (0.0 to 1.0).
/// Returns 0.0 if signatures have different lengths or are empty.
#[wasm_bindgen]
pub fn minhash_jaccard_from_signatures(sig_a: &[u32], sig_b: &[u32]) -> f64 {
    if sig_a.len() != sig_b.len() || sig_a.is_empty() {
        return 0.0;
    }

    // Check for empty signatures (all MAX)
    let empty_a = sig_a.iter().all(|&v| v == u32::MAX);
    let empty_b = sig_b.iter().all(|&v| v == u32::MAX);
    if empty_a || empty_b {
        return 0.0;
    }

    let matches = sig_a.iter().zip(sig_b.iter())
        .filter(|(&a, &b)| a == b)
        .count();

    matches as f64 / sig_a.len() as f64
}

// ============================================================================
// DotPlot Kernel (flat Float32 buffers, no substring allocations)
// See: phage_explorer-gim2.1.1
// ============================================================================

#[inline(always)]
fn dotplot_upper_ascii(byte: u8) -> u8 {
    if byte >= b'a' && byte <= b'z' {
        byte - 32
    } else {
        byte
    }
}

#[inline(always)]
fn dotplot_complement_upper(byte: u8) -> u8 {
    // Must match `packages/core/src/codons.ts::reverseComplement` behavior for uppercase inputs.
    match byte {
        b'A' => b'T',
        b'T' => b'A',
        b'G' => b'C',
        b'C' => b'G',
        // Ambiguity codes (IUPAC)
        b'N' => b'N',
        b'R' => b'Y',
        b'Y' => b'R',
        b'S' => b'S',
        b'W' => b'W',
        b'K' => b'M',
        b'M' => b'K',
        b'B' => b'V',
        b'D' => b'H',
        b'H' => b'D',
        b'V' => b'B',
        // Keep unknown chars as-is (matches JS fallback path).
        _ => byte,
    }
}

/// Result buffers for dotplot computation.
///
/// # Ownership
/// The caller must call `.free()` to release WASM memory.
#[wasm_bindgen]
pub struct DotPlotBuffers {
    direct: Vec<f32>,
    inverted: Vec<f32>,
    bins: usize,
    window: usize,
}

#[wasm_bindgen]
impl DotPlotBuffers {
    /// Flattened direct identity values (row-major, bins*bins).
    #[wasm_bindgen(getter)]
    pub fn direct(&self) -> js_sys::Float32Array {
        let arr = js_sys::Float32Array::new_with_length(self.direct.len() as u32);
        arr.copy_from(&self.direct);
        arr
    }

    /// Flattened inverted identity values (row-major, bins*bins).
    #[wasm_bindgen(getter)]
    pub fn inverted(&self) -> js_sys::Float32Array {
        let arr = js_sys::Float32Array::new_with_length(self.inverted.len() as u32);
        arr.copy_from(&self.inverted);
        arr
    }

    #[wasm_bindgen(getter)]
    pub fn bins(&self) -> usize {
        self.bins
    }

    #[wasm_bindgen(getter)]
    pub fn window(&self) -> usize {
        self.window
    }
}

/// Compute dotplot identity buffers for a sequence against itself.
///
/// Matches the semantics of `packages/core/src/analysis/dot-plot.ts` but avoids substring
/// allocations and object-heavy grids by returning flat typed arrays.
///
/// # Arguments
/// * `seq` - Sequence bytes (ASCII). Case-insensitive, U treated as T.
/// * `bins` - Plot resolution (bins x bins). If 0, returns empty buffers.
/// * `window` - Window size in bases. If 0, derives a conservative default similar to JS.
///
/// # Output layout
/// Row-major, with index `i*bins + j`.
#[wasm_bindgen]
pub fn dotplot_self_buffers(seq: &[u8], bins: usize, window: usize) -> DotPlotBuffers {
    if seq.is_empty() || bins == 0 {
        return DotPlotBuffers {
            direct: Vec::new(),
            inverted: Vec::new(),
            bins: 0,
            window: 0,
        };
    }

    // Uppercase once for JS parity: core `computeDotPlot` uses `sequence.toUpperCase()`.
    let upper: Vec<u8> = seq.iter().copied().map(dotplot_upper_ascii).collect();
    let len = upper.len();

    // Match JS default: max(20, floor(len/bins) || len), clamped to [1, len].
    let derived_window = {
        let base = if bins > 0 { len / bins } else { len };
        let base = if base == 0 { len } else { base };
        std::cmp::max(20usize, base)
    };
    let window = if window == 0 { derived_window } else { window };
    let window = std::cmp::max(1usize, std::cmp::min(len, window));

    // Precompute starts[] exactly like JS: floor(i * step) where step is float.
    let mut starts: Vec<usize> = vec![0; bins];
    if bins > 1 {
        let span = (len - window) as f64;
        let step = span / (bins as f64 - 1.0);
        for i in 0..bins {
            let s = ((i as f64) * step).floor() as usize;
            starts[i] = std::cmp::min(s, len - window);
        }
    } else if bins == 1 {
        starts[0] = 0;
    }

    let n = bins * bins;
    let mut direct = vec![0.0f32; n];
    let mut inverted = vec![0.0f32; n];
    let denom = window as f32;

    for i in 0..bins {
        let a0 = starts[i];

        for j in i..bins {
            let b0 = starts[j];

            let mut same_dir: u32 = 0;
            let mut same_inv: u32 = 0;

            // Direct: compare aligned window positions.
            // Inverted: compare reverse-complement of A window against B.
            for k in 0..window {
                let a = upper[a0 + k];
                let b = upper[b0 + k];
                if a == b {
                    same_dir += 1;
                }

                let a_rc = dotplot_complement_upper(upper[a0 + (window - 1 - k)]);
                if a_rc == b {
                    same_inv += 1;
                }
            }

            let dir_val = (same_dir as f32) / denom;
            let inv_val = (same_inv as f32) / denom;

            let idx1 = i * bins + j;
            direct[idx1] = dir_val;
            inverted[idx1] = inv_val;

            if i != j {
                let idx2 = j * bins + i;
                direct[idx2] = dir_val;
                inverted[idx2] = inv_val;
            }
        }
    }

    DotPlotBuffers {
        direct,
        inverted,
        bins,
        window,
    }
}

#[cfg(test)]
mod dotplot_tests {
    use super::*;

    #[test]
    fn dotplot_self_buffers_matches_expected_acgt() {
        // Mirrors `packages/core/src/analysis/dot-plot.test.ts` expectations.
        let result = dotplot_self_buffers(b"ACGT", 2, 2);

        assert_eq!(result.bins, 2);
        assert_eq!(result.window, 2);
        assert_eq!(result.direct.len(), 4);
        assert_eq!(result.inverted.len(), 4);

        // Row-major indices:
        // (0,0)=0 (0,1)=1
        // (1,0)=2 (1,1)=3
        assert!((result.direct[0] - 1.0).abs() < 1e-6);
        assert!((result.inverted[0] - 0.0).abs() < 1e-6);

        assert!((result.direct[1] - 0.0).abs() < 1e-6);
        assert!((result.inverted[1] - 1.0).abs() < 1e-6);

        assert!((result.direct[2] - 0.0).abs() < 1e-6);
        assert!((result.inverted[2] - 1.0).abs() < 1e-6);

        assert!((result.direct[3] - 1.0).abs() < 1e-6);
        assert!((result.inverted[3] - 0.0).abs() < 1e-6);
    }
}

// ============================================================================
// PCA (Principal Component Analysis) via Power Iteration
// Optimized matrix operations for high-dimensional genomic data
// ============================================================================

/// Result of PCA computation
#[wasm_bindgen]
pub struct PCAResult {
    /// Flattened eigenvectors (n_components * n_features), row-major
    eigenvectors: Vec<f64>,
    /// Eigenvalues for each component
    eigenvalues: Vec<f64>,
    /// Number of components computed
    n_components: usize,
    /// Number of features (dimensions)
    n_features: usize,
}

#[wasm_bindgen]
impl PCAResult {
    /// Get eigenvectors as flat array (row-major: [pc1_feat1, pc1_feat2, ..., pc2_feat1, ...])
    #[wasm_bindgen(getter)]
    pub fn eigenvectors(&self) -> Vec<f64> {
        self.eigenvectors.clone()
    }

    /// Get eigenvalues
    #[wasm_bindgen(getter)]
    pub fn eigenvalues(&self) -> Vec<f64> {
        self.eigenvalues.clone()
    }

    /// Number of components
    #[wasm_bindgen(getter)]
    pub fn n_components(&self) -> usize {
        self.n_components
    }

    /// Number of features
    #[wasm_bindgen(getter)]
    pub fn n_features(&self) -> usize {
        self.n_features
    }
}

/// Compute PCA using power iteration method.
///
/// # Arguments
/// * `data` - Flattened row-major matrix (n_samples * n_features)
/// * `n_samples` - Number of samples (rows)
/// * `n_features` - Number of features (columns)
/// * `n_components` - Number of principal components to extract
/// * `max_iterations` - Maximum iterations for power iteration (default: 100)
/// * `tolerance` - Convergence tolerance (default: 1e-8)
///
/// # Returns
/// PCAResult containing eigenvectors and eigenvalues.
///
/// # Algorithm
/// Uses power iteration to find top eigenvectors of X^T * X without forming
/// the full covariance matrix. This is memory-efficient for high-dimensional
/// data (e.g., k-mer frequencies with 4^k features).
#[wasm_bindgen]
pub fn pca_power_iteration(
    data: &[f64],
    n_samples: usize,
    n_features: usize,
    n_components: usize,
    max_iterations: usize,
    tolerance: f64,
) -> PCAResult {
    if data.len() != n_samples * n_features || n_samples == 0 || n_features == 0 {
        return PCAResult {
            eigenvectors: Vec::new(),
            eigenvalues: Vec::new(),
            n_components: 0,
            n_features,
        };
    }

    let max_iter = if max_iterations == 0 { 100 } else { max_iterations };
    let tol = if tolerance <= 0.0 { 1e-8 } else { tolerance };
    let n_comp = n_components.min(n_samples).min(n_features);

    // Compute mean for each feature
    let mut mean = vec![0.0; n_features];
    for i in 0..n_samples {
        let row_start = i * n_features;
        for j in 0..n_features {
            mean[j] += data[row_start + j];
        }
    }
    for j in 0..n_features {
        mean[j] /= n_samples as f64;
    }

    // Center the data (create centered copy)
    let mut centered = vec![0.0; n_samples * n_features];
    for i in 0..n_samples {
        let row_start = i * n_features;
        for j in 0..n_features {
            centered[row_start + j] = data[row_start + j] - mean[j];
        }
    }

    // Find principal components
    let mut eigenvectors = Vec::with_capacity(n_comp * n_features);
    let mut eigenvalues = Vec::with_capacity(n_comp);
    let mut previous_components: Vec<Vec<f64>> = Vec::new();

    for _ in 0..n_comp {
        let (eigenvector, eigenvalue) = power_iteration_single(
            &centered,
            n_samples,
            n_features,
            &previous_components,
            max_iter,
            tol,
        );

        eigenvectors.extend(&eigenvector);
        eigenvalues.push(eigenvalue);
        previous_components.push(eigenvector);
    }

    PCAResult {
        eigenvectors,
        eigenvalues,
        n_components: n_comp,
        n_features,
    }
}

/// Single power iteration to find one eigenvector
fn power_iteration_single(
    centered: &[f64],
    n_samples: usize,
    n_features: usize,
    previous_components: &[Vec<f64>],
    max_iterations: usize,
    tolerance: f64,
) -> (Vec<f64>, f64) {
    // Initialize with pseudo-random vector (deterministic for reproducibility)
    let mut v: Vec<f64> = (0..n_features)
        .map(|i| ((i * 7919 + 104729) % 1000) as f64 / 1000.0 - 0.5)
        .collect();

    // Remove projections onto previous components
    for pc in previous_components {
        deflate_vec(&mut v, pc);
    }
    normalize_vec(&mut v);

    let mut eigenvalue = 0.0;

    for _ in 0..max_iterations {
        // Compute X^T * X * v = X^T * (X * v)
        // First: Xv = X * v (n_samples x 1)
        let xv = multiply_xv(centered, &v, n_samples, n_features);

        // Then: X^T * Xv (n_features x 1)
        let mut xtxv = multiply_xt_u(centered, &xv, n_samples, n_features);

        // Remove projections onto previous components
        for pc in previous_components {
            deflate_vec(&mut xtxv, pc);
        }

        // Compute eigenvalue (Rayleigh quotient)
        let new_eigenvalue = dot_product_vec(&v, &xtxv);

        // Normalize to get new eigenvector estimate
        normalize_vec(&mut xtxv);

        // Align sign to avoid oscillation (v and -v represent the same eigenvector).
        if dot_product_vec(&v, &xtxv) < 0.0 {
            for x in xtxv.iter_mut() {
                *x = -*x;
            }
        }

        // Check convergence
        let diff: f64 = v.iter().zip(xtxv.iter()).map(|(a, b)| (a - b).abs()).sum();

        v = xtxv;
        eigenvalue = new_eigenvalue;

        if diff < tolerance {
            break;
        }
    }

    // Scale eigenvalue by (n_samples - 1) for sample covariance
    let scaled_eigenvalue = if n_samples > 1 {
        eigenvalue / (n_samples - 1) as f64
    } else {
        eigenvalue
    };

    (v, scaled_eigenvalue)
}

/// Multiply X (row-major, n x d) by vector v (d x 1), returns (n x 1)
fn multiply_xv(x: &[f64], v: &[f64], n_samples: usize, n_features: usize) -> Vec<f64> {
    let mut result = vec![0.0; n_samples];
    for i in 0..n_samples {
        let row_start = i * n_features;
        let mut sum = 0.0;
        for j in 0..n_features {
            sum += x[row_start + j] * v[j];
        }
        result[i] = sum;
    }
    result
}

/// Multiply X^T (d x n) by vector u (n x 1), returns (d x 1)
fn multiply_xt_u(x: &[f64], u: &[f64], n_samples: usize, n_features: usize) -> Vec<f64> {
    let mut result = vec![0.0; n_features];
    for i in 0..n_samples {
        let row_start = i * n_features;
        let ui = u[i];
        for j in 0..n_features {
            result[j] += x[row_start + j] * ui;
        }
    }
    result
}

/// Remove projection of v onto u: v = v - (vÂ·u) * u
fn deflate_vec(v: &mut [f64], u: &[f64]) {
    let proj = dot_product_vec(v, u);
    for i in 0..v.len() {
        v[i] -= proj * u[i];
    }
}

/// Normalize vector in place to unit length
fn normalize_vec(v: &mut [f64]) {
    let norm: f64 = v.iter().map(|x| x * x).sum::<f64>().sqrt();
    if norm > 0.0 {
        for x in v.iter_mut() {
            *x /= norm;
        }
    }
}

/// Dot product of two vectors
fn dot_product_vec(a: &[f64], b: &[f64]) -> f64 {
    a.iter().zip(b.iter()).map(|(x, y)| x * y).sum()
}

// ============================================================================
// PCA (f32) - optimized ABI for JS Float32Array inputs
// ============================================================================

/// PCA result buffers in f32.
///
/// # Ownership
/// The caller must call `.free()` to release WASM memory.
#[wasm_bindgen]
pub struct PCAResultF32 {
    eigenvectors: Vec<f32>,
    eigenvalues: Vec<f32>,
    mean: Vec<f32>,
    total_variance: f32,
    n_components: usize,
    n_features: usize,
}

#[wasm_bindgen]
impl PCAResultF32 {
    /// Eigenvectors as flat array (row-major: [pc1_feat1, pc1_feat2, ..., pc2_feat1, ...]).
    #[wasm_bindgen(getter)]
    pub fn eigenvectors(&self) -> js_sys::Float32Array {
        let arr = js_sys::Float32Array::new_with_length(self.eigenvectors.len() as u32);
        arr.copy_from(&self.eigenvectors);
        arr
    }

    /// Eigenvalues (sample-covariance scale, i.e. divided by (n_samples - 1) when n_samples > 1).
    #[wasm_bindgen(getter)]
    pub fn eigenvalues(&self) -> js_sys::Float32Array {
        let arr = js_sys::Float32Array::new_with_length(self.eigenvalues.len() as u32);
        arr.copy_from(&self.eigenvalues);
        arr
    }

    /// Mean vector used for centering.
    #[wasm_bindgen(getter)]
    pub fn mean(&self) -> js_sys::Float32Array {
        let arr = js_sys::Float32Array::new_with_length(self.mean.len() as u32);
        arr.copy_from(&self.mean);
        arr
    }

    /// Total variance of centered data (sample-covariance scale).
    #[wasm_bindgen(getter)]
    pub fn total_variance(&self) -> f32 {
        self.total_variance
    }

    #[wasm_bindgen(getter)]
    pub fn n_components(&self) -> usize {
        self.n_components
    }

    #[wasm_bindgen(getter)]
    pub fn n_features(&self) -> usize {
        self.n_features
    }
}

/// Compute PCA using power iteration (f32 data path).
///
/// This entrypoint is designed to accept JS `Float32Array` inputs without the caller
/// having to upcast to `Float64Array`.
///
/// Determinism:
/// - Initialization is deterministic (no randomness).
/// - Output eigenvectors are canonicalized to a stable sign (largest-magnitude element is positive).
#[wasm_bindgen]
pub fn pca_power_iteration_f32(
    data: &[f32],
    n_samples: usize,
    n_features: usize,
    n_components: usize,
    max_iterations: usize,
    tolerance: f32,
) -> PCAResultF32 {
    if data.len() != n_samples * n_features || n_samples == 0 || n_features == 0 {
        return PCAResultF32 {
            eigenvectors: Vec::new(),
            eigenvalues: Vec::new(),
            mean: Vec::new(),
            total_variance: 0.0,
            n_components: 0,
            n_features,
        };
    }

    let max_iter = if max_iterations == 0 { 100 } else { max_iterations };
    let tol = if tolerance <= 0.0 { 1e-8 } else { tolerance };
    let n_comp = n_components.min(n_samples).min(n_features);

    // Compute mean for each feature
    let mut mean = vec![0.0f32; n_features];
    for i in 0..n_samples {
        let row_start = i * n_features;
        for j in 0..n_features {
            mean[j] += data[row_start + j];
        }
    }
    let inv_n = 1.0f32 / (n_samples as f32);
    for j in 0..n_features {
        mean[j] *= inv_n;
    }

    // Center the data (create centered copy)
    let mut centered = vec![0.0f32; n_samples * n_features];
    for i in 0..n_samples {
        let row_start = i * n_features;
        for j in 0..n_features {
            centered[row_start + j] = data[row_start + j] - mean[j];
        }
    }

    // Total variance (sample covariance scaling) for explained variance ratios.
    let mut total_variance = 0.0f32;
    for i in 0..(n_samples * n_features) {
        total_variance += centered[i] * centered[i];
    }
    total_variance /= n_samples.saturating_sub(1).max(1) as f32;

    // Find principal components
    let mut eigenvectors = Vec::with_capacity(n_comp * n_features);
    let mut eigenvalues = Vec::with_capacity(n_comp);
    let mut previous_components: Vec<Vec<f32>> = Vec::new();

    for _ in 0..n_comp {
        let (eigenvector, eigenvalue) = power_iteration_single_f32(
            &centered,
            n_samples,
            n_features,
            &previous_components,
            max_iter,
            tol,
        );

        eigenvectors.extend_from_slice(&eigenvector);
        eigenvalues.push(eigenvalue);
        previous_components.push(eigenvector);
    }

    PCAResultF32 {
        eigenvectors,
        eigenvalues,
        mean,
        total_variance,
        n_components: n_comp,
        n_features,
    }
}

fn power_iteration_single_f32(
    centered: &[f32],
    n_samples: usize,
    n_features: usize,
    previous_components: &[Vec<f32>],
    max_iterations: usize,
    tolerance: f32,
) -> (Vec<f32>, f32) {
    // Deterministic pseudo-random initialization (mirrors f64 PCA init but stays in f32).
    let mut v: Vec<f32> = (0..n_features)
        .map(|i| {
            let seed = ((i as u64).wrapping_mul(7919).wrapping_add(104729) % 1000) as f32;
            seed / 1000.0 - 0.5
        })
        .collect();

    // Remove projections onto previous components
    for pc in previous_components {
        deflate_vec_f32(&mut v, pc);
    }
    normalize_vec_f32(&mut v);

    let mut eigenvalue = 0.0f32;

    for _ in 0..max_iterations {
        // Compute X^T * X * v = X^T * (X * v)
        let xv = multiply_xv_f32(centered, &v, n_samples, n_features);
        let mut xtxv = multiply_xt_u_f32(centered, &xv, n_samples, n_features);

        // Remove projections onto previous components
        for pc in previous_components {
            deflate_vec_f32(&mut xtxv, pc);
        }

        // Compute eigenvalue (Rayleigh quotient)
        let new_eigenvalue = dot_product_vec_f32(&v, &xtxv);

        // Normalize to get new eigenvector estimate
        normalize_vec_f32(&mut xtxv);

        // Align sign to avoid oscillation (v and -v represent the same eigenvector).
        if dot_product_vec_f32(&v, &xtxv) < 0.0 {
            for x in xtxv.iter_mut() {
                *x = -*x;
            }
        }

        // Check convergence
        let mut diff = 0.0f32;
        for i in 0..n_features {
            diff += (v[i] - xtxv[i]).abs();
        }

        v = xtxv;
        eigenvalue = new_eigenvalue;

        if diff < tolerance {
            break;
        }
    }

    // Canonicalize sign for deterministic output: largest-magnitude entry is positive.
    canonicalize_sign_f32(&mut v);

    // Scale eigenvalue by (n_samples - 1) for sample covariance
    let scaled_eigenvalue = if n_samples > 1 {
        eigenvalue / (n_samples - 1) as f32
    } else {
        eigenvalue
    };

    (v, scaled_eigenvalue)
}

fn canonicalize_sign_f32(v: &mut [f32]) {
    if v.is_empty() {
        return;
    }
    let mut max_idx = 0usize;
    let mut max_abs = v[0].abs();
    for (i, &x) in v.iter().enumerate().skip(1) {
        let ax = x.abs();
        if ax > max_abs {
            max_abs = ax;
            max_idx = i;
        }
    }
    if v[max_idx] < 0.0 {
        for x in v.iter_mut() {
            *x = -*x;
        }
    }
}

fn multiply_xv_f32(x: &[f32], v: &[f32], n_samples: usize, n_features: usize) -> Vec<f32> {
    let mut result = vec![0.0f32; n_samples];
    for i in 0..n_samples {
        let row_start = i * n_features;
        let mut sum = 0.0f32;
        for j in 0..n_features {
            sum += x[row_start + j] * v[j];
        }
        result[i] = sum;
    }
    result
}

fn multiply_xt_u_f32(x: &[f32], u: &[f32], n_samples: usize, n_features: usize) -> Vec<f32> {
    let mut result = vec![0.0f32; n_features];
    for i in 0..n_samples {
        let row_start = i * n_features;
        let ui = u[i];
        for j in 0..n_features {
            result[j] += x[row_start + j] * ui;
        }
    }
    result
}

fn deflate_vec_f32(v: &mut [f32], u: &[f32]) {
    let proj = dot_product_vec_f32(v, u);
    for i in 0..v.len() {
        v[i] -= proj * u[i];
    }
}

fn normalize_vec_f32(v: &mut [f32]) {
    let mut norm = 0.0f32;
    for &x in v.iter() {
        norm += x * x;
    }
    norm = norm.sqrt();

    if norm > 0.0 {
        let inv = 1.0f32 / norm;
        for x in v.iter_mut() {
            *x *= inv;
        }
    }
}

fn dot_product_vec_f32(a: &[f32], b: &[f32]) -> f32 {
    let mut sum = 0.0f32;
    for i in 0..a.len().min(b.len()) {
        sum += a[i] * b[i];
    }
    sum
}

// ============================================================================
// Hoeffding's D - Measures statistical dependence between two vectors
// Based on: https://github.com/Dicklesworthstone/fast_vector_similarity
// ============================================================================

/// Compute average ranks for a vector, handling ties correctly.
/// Returns a vector of ranks where ties receive the average of their positions.
fn average_rank(data: &[f64]) -> Vec<f64> {
    let n = data.len();
    if n == 0 {
        return Vec::new();
    }

    // Create index-value pairs and sort by value
    let mut indexed: Vec<(usize, f64)> = data.iter().cloned().enumerate().collect();
    indexed.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));

    let mut ranks = vec![0.0; n];
    let mut i = 0;

    while i < n {
        // Find all elements with the same value (ties)
        let mut j = i;
        let mut total_rank = 0.0;

        while j < n && indexed[j].1 == indexed[i].1 {
            total_rank += (j + 1) as f64; // Ranks are 1-based
            j += 1;
        }

        // Assign average rank to all tied elements
        let avg_rank = total_rank / (j - i) as f64;
        for k in i..j {
            ranks[indexed[k].0] = avg_rank;
        }

        i = j;
    }

    ranks
}

/// Result of Hoeffding's D computation
#[wasm_bindgen]
pub struct HoeffdingResult {
    /// Hoeffding's D statistic. Range: approximately [-0.5, 1]
    /// Values near 0 indicate independence, larger values indicate dependence.
    /// Unlike correlation, captures non-linear relationships.
    pub d: f64,
    /// Number of observations used
    pub n: usize,
}

/// Compute Hoeffding's D statistic for measuring statistical dependence.
///
/// Hoeffding's D is a non-parametric measure of association that can detect
/// any type of dependence (linear or non-linear) between two variables.
/// Unlike Pearson correlation (linear only) or Spearman/Kendall (monotonic),
/// Hoeffding's D can detect complex non-monotonic relationships.
///
/// # Arguments
/// * `x` - First vector of observations (as a JS Float64Array)
/// * `y` - Second vector of observations (must have same length as x)
///
/// # Returns
/// HoeffdingResult containing the D statistic and sample size.
/// D ranges approximately from -0.5 to 1, where:
/// - D â 0: variables are independent
/// - D > 0: variables are dependent
/// - D = 1: perfect dependence
///
/// # Performance
/// O(nÂ²) time complexity. For very large vectors (n > 10000), consider
/// sampling or using approximate methods.
///
/// # Example Use Cases for Genome Analysis
/// - Compare k-mer frequency vectors between genomes
/// - Detect non-linear relationships in GC content distributions
/// - Measure codon usage similarity accounting for complex dependencies
#[wasm_bindgen]
pub fn hoeffdings_d(x: &[f64], y: &[f64]) -> HoeffdingResult {
    let n = x.len();

    // Handle edge cases
    if n != y.len() || n < 5 {
        return HoeffdingResult { d: 0.0, n };
    }

    let nf = n as f64;

    // Compute ranks (1-based, with ties handled via average)
    let r = average_rank(x);
    let s = average_rank(y);

    // Compute Q values for each observation
    // Q[i] = 1 + (number of points with both x and y less than point i)
    //        + 0.25 * (number of points with both x and y equal to point i, excluding i itself)
    //        + 0.5 * (number of points with x equal and y less, plus x less and y equal)
    let mut q = vec![0.0; n];

    for i in 0..n {
        let ri = r[i];
        let si = s[i];

        let mut less_than = 0.0;
        let mut equal_both = 0.0;
        let mut equal_r = 0.0;
        let mut equal_s = 0.0;

        for j in 0..n {
            if i == j {
                continue;
            }

            let rj = r[j];
            let sj = s[j];

            if rj < ri && sj < si {
                less_than += 1.0;
            } else if rj == ri && sj == si {
                equal_both += 1.0;
            } else if rj == ri && sj < si {
                equal_r += 1.0;
            } else if rj < ri && sj == si {
                equal_s += 1.0;
            }
        }

        q[i] = 1.0 + less_than + 0.25 * equal_both + 0.5 * (equal_r + equal_s);
    }

    // Compute the three D terms
    // D1 = sum of (Q[i] - 1) * (Q[i] - 3)
    // Note: This is (Q-1) * ((Q-1) - 2), matching the standard Hoeffding's D formula
    let d1: f64 = q.iter().map(|&qi| (qi - 1.0) * (qi - 3.0)).sum();

    // D2 = sum of (R[i] - 1) * (R[i] - 2) * (S[i] - 1) * (S[i] - 2)
    let d2: f64 = r.iter()
        .zip(s.iter())
        .map(|(&ri, &si)| (ri - 1.0) * (ri - 2.0) * (si - 1.0) * (si - 2.0))
        .sum();

    // D3 = sum of (R[i] - 1) * (S[i] - 1) * (Q[i] - 1)
    let d3: f64 = r.iter()
        .zip(s.iter())
        .zip(q.iter())
        .map(|((&ri, &si), &qi)| (ri - 1.0) * (si - 1.0) * (qi - 1.0))
        .sum();

    // Hoeffding's D formula
    // D = 30 * ((n-2)(n-3) * D1 + D2 - 2(n-2) * D3) / (n(n-1)(n-2)(n-3)(n-4))
    let denom = nf * (nf - 1.0) * (nf - 2.0) * (nf - 3.0) * (nf - 4.0);
    let numerator = 30.0 * ((nf - 2.0) * (nf - 3.0) * d1 + d2 - 2.0 * (nf - 2.0) * d3);

    let d = if denom.abs() > 1e-10 {
        numerator / denom
    } else {
        0.0
    };

    HoeffdingResult { d, n }
}

/// Compute Hoeffding's D between two k-mer frequency vectors derived from sequences.
///
/// This is a convenience function that:
/// 1. Extracts k-mer frequencies from both sequences
/// 2. Creates aligned frequency vectors for all unique k-mers
/// 3. Computes Hoeffding's D on the frequency vectors
///
/// # Arguments
/// * `sequence_a` - First DNA sequence
/// * `sequence_b` - Second DNA sequence
/// * `k` - K-mer size (typically 3-7 for genome comparison)
///
/// # Returns
/// Hoeffding's D statistic measuring dependence between k-mer frequency profiles.
/// Higher values indicate more similar frequency patterns (non-linear similarity).
#[wasm_bindgen]
pub fn kmer_hoeffdings_d(sequence_a: &str, sequence_b: &str, k: usize) -> HoeffdingResult {
    if k == 0 {
        return HoeffdingResult { d: 0.0, n: 0 };
    }

    let freqs_a = extract_kmer_freqs(sequence_a, k);
    let freqs_b = extract_kmer_freqs(sequence_b, k);

    if freqs_a.is_empty() && freqs_b.is_empty() {
        return HoeffdingResult { d: 1.0, n: 0 }; // Both empty = perfect agreement
    }

    // Build aligned vectors: include all k-mers from both sequences
    let mut all_kmers: Vec<&String> = freqs_a.keys().chain(freqs_b.keys()).collect();
    all_kmers.sort();
    all_kmers.dedup();

    let n = all_kmers.len();
    if n < 5 {
        // Not enough data points for meaningful Hoeffding's D
        return HoeffdingResult { d: 0.0, n };
    }

    let x: Vec<f64> = all_kmers.iter()
        .map(|kmer| *freqs_a.get(*kmer).unwrap_or(&0) as f64)
        .collect();
    let y: Vec<f64> = all_kmers.iter()
        .map(|kmer| *freqs_b.get(*kmer).unwrap_or(&0) as f64)
        .collect();

    hoeffdings_d(&x, &y)
}

// ============================================================================
// Entropy Functions - Information-theoretic sequence analysis
// ============================================================================

/// Compute Shannon entropy from a probability distribution.
///
/// H(X) = -Î£ p(x) * log2(p(x))
///
/// # Arguments
/// * `probs` - Probability distribution (must sum to ~1.0)
///
/// # Returns
/// Shannon entropy in bits. Returns 0 for empty or invalid input.
#[wasm_bindgen]
pub fn shannon_entropy(probs: &[f64]) -> f64 {
    if probs.is_empty() {
        return 0.0;
    }

    let mut entropy = 0.0;
    for &p in probs {
        if p > 0.0 && p <= 1.0 {
            entropy -= p * p.log2();
        }
    }

    // Clamp to non-negative (numerical precision issues can make it slightly negative)
    entropy.max(0.0)
}

/// Compute Shannon entropy from a frequency count array.
/// Converts counts to probabilities internally.
///
/// # Arguments
/// * `counts` - Array of frequency counts
///
/// # Returns
/// Shannon entropy in bits.
#[wasm_bindgen]
pub fn shannon_entropy_from_counts(counts: &[f64]) -> f64 {
    let total: f64 = counts.iter().sum();
    if total <= 0.0 {
        return 0.0;
    }

    let mut entropy = 0.0;
    for &count in counts {
        if count > 0.0 {
            let p = count / total;
            entropy -= p * p.log2();
        }
    }

    entropy.max(0.0)
}

/// Compute Jensen-Shannon Divergence between two probability distributions.
///
/// JSD(P || Q) = 0.5 * KL(P || M) + 0.5 * KL(Q || M)
/// where M = 0.5 * (P + Q)
///
/// This is a symmetric and bounded (0 to 1 when using log2) divergence measure.
///
/// # Arguments
/// * `p` - First probability distribution
/// * `q` - Second probability distribution (must have same length as p)
///
/// # Returns
/// JSD value in range [0, 1]. Returns 0 if inputs are identical, 1 if completely different.
#[wasm_bindgen]
pub fn jensen_shannon_divergence(p: &[f64], q: &[f64]) -> f64 {
    if p.len() != q.len() || p.is_empty() {
        return 0.0;
    }

    let n = p.len();
    let mut jsd = 0.0;

    for i in 0..n {
        let pi = p[i].max(0.0);
        let qi = q[i].max(0.0);
        let mi = 0.5 * (pi + qi);

        if mi > 0.0 {
            if pi > 0.0 {
                jsd += 0.5 * pi * (pi / mi).log2();
            }
            if qi > 0.0 {
                jsd += 0.5 * qi * (qi / mi).log2();
            }
        }
    }

    // Clamp to valid range [0, 1]
    jsd.max(0.0).min(1.0)
}

/// Compute JSD between two count arrays.
/// Normalizes to probabilities internally.
#[wasm_bindgen]
pub fn jensen_shannon_divergence_from_counts(counts_a: &[f64], counts_b: &[f64]) -> f64 {
    if counts_a.len() != counts_b.len() || counts_a.is_empty() {
        return 0.0;
    }

    let total_a: f64 = counts_a.iter().sum();
    let total_b: f64 = counts_b.iter().sum();

    if total_a <= 0.0 || total_b <= 0.0 {
        return if total_a <= 0.0 && total_b <= 0.0 { 0.0 } else { 1.0 };
    }

    let p: Vec<f64> = counts_a.iter().map(|&c| c / total_a).collect();
    let q: Vec<f64> = counts_b.iter().map(|&c| c / total_b).collect();

    jensen_shannon_divergence(&p, &q)
}

// ============================================================================
// Repeat Detection - Palindromes and Tandem Repeats
// ============================================================================

/// Result of repeat detection
#[wasm_bindgen]
pub struct RepeatResult {
    /// JSON-encoded array of detected repeats
    json: String,
}

#[wasm_bindgen]
impl RepeatResult {
    #[wasm_bindgen(getter)]
    pub fn json(&self) -> String {
        self.json.clone()
    }
}

/// Detect palindromic (inverted repeat) sequences in DNA.
///
/// A palindrome in DNA is a sequence that reads the same on the complementary
/// strand in reverse (e.g., GAATTC and its complement CTTAAG reversed).
///
/// # Arguments
/// * `seq` - DNA sequence string
/// * `min_len` - Minimum palindrome arm length (typically 4-6)
/// * `max_gap` - Maximum gap/spacer between palindrome arms (0 for perfect palindromes)
///
/// # Returns
/// RepeatResult with JSON array of {start, end, arm_length, gap, sequence}
#[wasm_bindgen]
pub fn detect_palindromes(seq: &str, min_len: usize, max_gap: usize) -> RepeatResult {
    let bytes = seq.as_bytes();
    let n = bytes.len();
    let mut results: Vec<String> = Vec::new();

    if n < min_len * 2 {
        return RepeatResult { json: "[]".to_string() };
    }

    // Check every potential center position
    for center in min_len..(n - min_len + 1) {
        for gap in 0..=max_gap {
            if center < min_len + gap / 2 || center + gap / 2 + min_len > n {
                continue;
            }

            let half_gap = gap / 2;
            let mut arm_len = 0;

            // Expand outward checking for complementary bases
            for offset in 0..min_len.max((n - center - half_gap).min(center - half_gap)) {
                let left_idx = center - half_gap - offset - 1;
                let right_idx = center + half_gap + offset;

                if right_idx >= n {
                    break;
                }

                let left_base = bytes[left_idx];
                let right_base = bytes[right_idx];

                if is_complement(left_base, right_base) {
                    arm_len = offset + 1;
                } else {
                    break;
                }
            }

            if arm_len >= min_len {
                let start = center - half_gap - arm_len;
                let end = center + half_gap + arm_len;
                let subseq = std::str::from_utf8(&bytes[start..end]).unwrap_or("");

                results.push(format!(
                    "{{\"start\":{},\"end\":{},\"arm_length\":{},\"gap\":{},\"sequence\":\"{}\"}}",
                    start, end, arm_len, gap, subseq
                ));
            }
        }
    }

    RepeatResult {
        json: format!("[{}]", results.join(",")),
    }
}

/// Check if two bases are complements
fn is_complement(a: u8, b: u8) -> bool {
    matches!(
        (a.to_ascii_uppercase(), b.to_ascii_uppercase()),
        (b'A', b'T') | (b'T', b'A') | (b'G', b'C') | (b'C', b'G') |
        (b'A', b'U') | (b'U', b'A')
    )
}

/// Detect tandem repeats (consecutive copies of a pattern).
///
/// # Arguments
/// * `seq` - DNA sequence string
/// * `min_unit` - Minimum repeat unit length
/// * `max_unit` - Maximum repeat unit length
/// * `min_copies` - Minimum number of consecutive copies
///
/// # Returns
/// RepeatResult with JSON array of {start, end, unit, copies, sequence}
#[wasm_bindgen]
pub fn detect_tandem_repeats(
    seq: &str,
    min_unit: usize,
    max_unit: usize,
    min_copies: usize,
) -> RepeatResult {
    let bytes = seq.as_bytes();
    let n = bytes.len();
    let mut results: Vec<String> = Vec::new();

    if n < min_unit * min_copies {
        return RepeatResult { json: "[]".to_string() };
    }

    // For each starting position
    for start in 0..n {
        // For each unit length
        for unit_len in min_unit..=max_unit.min(n - start) {
            let unit = &bytes[start..start + unit_len];

            // Count consecutive copies
            let mut copies = 1;
            let mut pos = start + unit_len;

            while pos + unit_len <= n {
                let candidate = &bytes[pos..pos + unit_len];
                if candidate.eq_ignore_ascii_case(unit) {
                    copies += 1;
                    pos += unit_len;
                } else {
                    break;
                }
            }

            if copies >= min_copies {
                let end = start + copies * unit_len;
                let unit_str = std::str::from_utf8(unit).unwrap_or("").to_uppercase();
                let subseq = std::str::from_utf8(&bytes[start..end]).unwrap_or("");

                results.push(format!(
                    "{{\"start\":{},\"end\":{},\"unit\":\"{}\",\"copies\":{},\"sequence\":\"{}\"}}",
                    start, end, unit_str, copies, subseq
                ));
            }
        }
    }

    RepeatResult {
        json: format!("[{}]", results.join(",")),
    }
}

// ============================================================================
// GC Skew and Sequence Complexity
// ============================================================================

/// Compute GC skew using a sliding window.
///
/// GC skew = (G - C) / (G + C)
///
/// GC skew is used to identify the origin and terminus of replication in
/// bacterial genomes. Positive skew indicates leading strand, negative
/// indicates lagging strand.
///
/// # Arguments
/// * `seq` - DNA sequence string
/// * `window_size` - Size of sliding window
/// * `step_size` - Step between windows (1 for maximum resolution)
///
/// # Returns
/// Array of GC skew values for each window position.
#[wasm_bindgen]
pub fn compute_gc_skew(seq: &str, window_size: usize, step_size: usize) -> Vec<f64> {
    let bytes = seq.as_bytes();
    let n = bytes.len();

    if window_size == 0 || step_size == 0 || n < window_size {
        return Vec::new();
    }

    let num_windows = (n - window_size) / step_size + 1;
    let mut results = Vec::with_capacity(num_windows);

    for i in 0..num_windows {
        let start = i * step_size;
        let window = &bytes[start..start + window_size];

        let mut g_count = 0u32;
        let mut c_count = 0u32;

        for &base in window {
            match base {
                b'G' | b'g' => g_count += 1,
                b'C' | b'c' => c_count += 1,
                _ => {}
            }
        }

        let total = g_count + c_count;
        let skew = if total > 0 {
            (g_count as f64 - c_count as f64) / total as f64
        } else {
            0.0
        };

        results.push(skew);
    }

    results
}

/// Compute cumulative GC skew (useful for visualizing replication origin).
///
/// The cumulative skew will have a minimum at the origin of replication
/// and maximum at the terminus.
#[wasm_bindgen]
pub fn compute_cumulative_gc_skew(seq: &str) -> Vec<f64> {
    let bytes = seq.as_bytes();
    let mut cumulative = Vec::with_capacity(bytes.len());
    let mut sum = 0.0;

    for &base in bytes {
        match base {
            b'G' | b'g' => sum += 1.0,
            b'C' | b'c' => sum -= 1.0,
            _ => {}
        }
        cumulative.push(sum);
    }

    cumulative
}

/// Compute linguistic complexity of a sequence.
///
/// Linguistic complexity = (number of distinct substrings) / (maximum possible substrings)
///
/// This measures how "random" or information-rich a sequence is.
/// Low complexity indicates repetitive regions.
///
/// # Arguments
/// * `seq` - DNA sequence string
/// * `max_k` - Maximum substring length to consider
///
/// # Returns
/// Complexity score in range [0, 1] where 1 = maximum complexity.
#[wasm_bindgen]
pub fn compute_linguistic_complexity(seq: &str, max_k: usize) -> f64 {
    let bytes = seq.as_bytes();
    let n = bytes.len();

    if n == 0 || max_k == 0 {
        return 0.0;
    }

    let max_k = max_k.min(n);
    let mut total_distinct = 0u64;
    let mut total_possible = 0u64;

    for k in 1..=max_k {
        let mut seen: std::collections::HashSet<&[u8]> = std::collections::HashSet::new();

        for i in 0..=n.saturating_sub(k) {
            seen.insert(&bytes[i..i + k]);
        }

        total_distinct += seen.len() as u64;

        // Maximum possible distinct k-mers is min(4^k, n-k+1) for DNA
        let max_possible = (4u64.pow(k as u32)).min((n - k + 1) as u64);
        total_possible += max_possible;
    }

    if total_possible == 0 {
        0.0
    } else {
        total_distinct as f64 / total_possible as f64
    }
}

/// Compute local complexity in sliding windows.
///
/// # Arguments
/// * `seq` - DNA sequence string
/// * `window_size` - Size of sliding window
/// * `step_size` - Step between windows
/// * `k` - K-mer size for complexity calculation
///
/// # Returns
/// Array of complexity values for each window.
#[wasm_bindgen]
pub fn compute_windowed_complexity(
    seq: &str,
    window_size: usize,
    step_size: usize,
    k: usize,
) -> Vec<f64> {
    let bytes = seq.as_bytes();
    let n = bytes.len();

    if window_size == 0 || step_size == 0 || k == 0 || n < window_size || k > window_size {
        return Vec::new();
    }

    let num_windows = (n - window_size) / step_size + 1;
    let mut results = Vec::with_capacity(num_windows);

    for i in 0..num_windows {
        let start = i * step_size;
        let window = &bytes[start..start + window_size];

        // Count distinct k-mers in this window
        let mut seen: std::collections::HashSet<&[u8]> = std::collections::HashSet::new();
        for j in 0..=window.len().saturating_sub(k) {
            seen.insert(&window[j..j + k]);
        }

        let distinct = seen.len() as f64;
        let max_possible = (4u64.pow(k as u32) as f64).min((window.len() - k + 1) as f64);

        let complexity = if max_possible > 0.0 {
            distinct / max_possible
        } else {
            0.0
        };

        results.push(complexity);
    }

    results
}

/// Compute normalized Shannon entropy (0..=1) in sliding windows over A/C/G/T bases.
///
/// Semantics match `packages/web/src/workers/analysis.worker.ts`:
/// - Non-ACGT bases are ignored (do not contribute to counts/total).
/// - Windows are taken at starts `i = 0, step, 2*step, ...` while `i < n - window_size`
///   (note: this intentionally excludes the final full window at `i = n - window_size`).
/// - Output values are Shannon entropy in bits divided by 2 (max for 4 symbols).
///
/// # Arguments
/// * `seq` - DNA sequence string (case-insensitive; U treated as T).
/// * `window_size` - Size of each window.
/// * `step_size` - Step between windows.
///
/// # Returns
/// Array of normalized entropy values (0..=1), one per window.
#[wasm_bindgen]
pub fn compute_windowed_entropy_acgt(
    seq: &str,
    window_size: usize,
    step_size: usize,
) -> Vec<f64> {
    let bytes = seq.as_bytes();
    let n = bytes.len();

    if window_size == 0 || step_size == 0 || n <= window_size {
        return Vec::new();
    }

    // Match the JS loop condition: `i < n - window_size`.
    let max_start_exclusive = n - window_size;
    if max_start_exclusive == 0 {
        return Vec::new();
    }

    let num_windows = (max_start_exclusive - 1) / step_size + 1;
    let mut out = Vec::with_capacity(num_windows);

    #[inline(always)]
    fn entropy_norm(counts: &[u32; 4], total: u32) -> f64 {
        if total == 0 {
            return 0.0;
        }
        let inv_total = 1.0 / (total as f64);
        let mut ent = 0.0;
        for &c in counts.iter() {
            if c == 0 {
                continue;
            }
            let p = (c as f64) * inv_total;
            ent -= p * p.log2();
        }
        ent / 2.0
    }

    // Initialize first window [0, window_size)
    let mut counts = [0u32; 4];
    let mut total = 0u32;
    for &b in &bytes[0..window_size] {
        let code = encode_base(b);
        if code <= SEQ_BASE_T {
            counts[code as usize] += 1;
            total += 1;
        }
    }
    out.push(entropy_norm(&counts, total));

    // If step >= window, windows don't overlap; recompute each time.
    if step_size >= window_size {
        for w in 1..num_windows {
            let start = w * step_size;
            let end = start + window_size;
            if end > n {
                break;
            }
            counts = [0u32; 4];
            total = 0u32;
            for &b in &bytes[start..end] {
                let code = encode_base(b);
                if code <= SEQ_BASE_T {
                    counts[code as usize] += 1;
                    total += 1;
                }
            }
            out.push(entropy_norm(&counts, total));
        }
        return out;
    }

    // Sliding update for overlapping windows.
    for w in 1..num_windows {
        let prev_start = (w - 1) * step_size;
        let remove_end = prev_start + step_size;
        let add_start = prev_start + window_size;
        let add_end = add_start + step_size;
        if add_end > n {
            break;
        }

        for &b in &bytes[prev_start..remove_end] {
            let code = encode_base(b);
            if code <= SEQ_BASE_T {
                counts[code as usize] = counts[code as usize].saturating_sub(1);
                total = total.saturating_sub(1);
            }
        }

        for &b in &bytes[add_start..add_end] {
            let code = encode_base(b);
            if code <= SEQ_BASE_T {
                counts[code as usize] += 1;
                total += 1;
            }
        }

        out.push(entropy_norm(&counts, total));
    }

    out
}

// ============================================================================
// Hilbert Curve Rendering (bytes-first, typed-array output)
// ============================================================================

const HILBERT_MIN_ORDER: u32 = 4;
// Keep memory bounded for interactive use (4096^2 RGBA = ~64MB; 2048^2 RGBA = ~16MB).
const HILBERT_MAX_ORDER: u32 = 11;
const HILBERT_MAX_RGBA_BYTES: usize = 32 * 1024 * 1024;

#[inline(always)]
fn hilbert_rot(n: u32, mut x: u32, mut y: u32, rx: u32, ry: u32) -> (u32, u32) {
    if ry == 0 {
        if rx == 1 {
            x = n - 1 - x;
            y = n - 1 - y;
        }
        // Swap x/y
        return (y, x);
    }
    (x, y)
}

#[inline(always)]
fn hilbert_d2xy(size: u32, mut d: u32) -> (u32, u32) {
    let mut x: u32 = 0;
    let mut y: u32 = 0;
    let mut s: u32 = 1;
    while s < size {
        let rx = (d >> 1) & 1;
        let ry = (d ^ rx) & 1;
        let (rx_x, rx_y) = hilbert_rot(s, x, y, rx, ry);
        x = rx_x + s * rx;
        y = rx_y + s * ry;
        d >>= 2;
        s <<= 1;
    }
    (x, y)
}

/// Render a Hilbert curve visualization as a flat RGBA buffer.
///
/// # Inputs
/// - `seq_bytes`: ASCII DNA/RNA bytes OR already-encoded ACGT05 (0..=4).
/// - `order`: Hilbert order (grid size = 2^order). Must be within guardrails.
/// - `colors_rgb`: packed RGB palette for [A,C,G,T,N] as 15 bytes.
///
/// # Output
/// - `Vec<u8>` interpreted as RGBA bytes (length = (2^order)^2 * 4).
///
/// # Guardrails
/// - Caps order to avoid OOM. Returns an empty vec if requested output would exceed limits.
#[wasm_bindgen]
pub fn hilbert_rgba(seq_bytes: &[u8], order: u32, colors_rgb: &[u8]) -> Vec<u8> {
    if seq_bytes.is_empty() {
        return Vec::new();
    }
    if colors_rgb.len() < 15 {
        return Vec::new();
    }
    if order < HILBERT_MIN_ORDER || order > HILBERT_MAX_ORDER {
        return Vec::new();
    }

    let size: u32 = 1u32 << order;
    let total_pixels: usize = (size as usize) * (size as usize);
    let total_bytes = total_pixels.saturating_mul(4);
    if total_bytes == 0 || total_bytes > HILBERT_MAX_RGBA_BYTES {
        return Vec::new();
    }

    let bg_r = colors_rgb[12];
    let bg_g = colors_rgb[13];
    let bg_b = colors_rgb[14];

    let mut out = vec![0u8; total_bytes];
    for px in out.chunks_exact_mut(4) {
        px[0] = bg_r;
        px[1] = bg_g;
        px[2] = bg_b;
        px[3] = 255;
    }

    let max_idx = std::cmp::min(seq_bytes.len(), total_pixels);
    for i in 0..max_idx {
        let raw = seq_bytes[i];
        // Accept either ASCII bytes or already-encoded ACGT05 (0..=4).
        let code_u8 = if raw <= 4 { raw } else { encode_base(raw) };
        let code = (code_u8 as usize).min(4);

        let (x, y) = hilbert_d2xy(size, i as u32);
        let idx = ((y as usize) * (size as usize) + (x as usize)) * 4;
        let c = code * 3;
        out[idx] = colors_rgb[c];
        out[idx + 1] = colors_rgb[c + 1];
        out[idx + 2] = colors_rgb[c + 2];
        out[idx + 3] = 255;
    }

    out
}

// ============================================================================
// Chaos Game Representation (CGR) rasterization (bytes-first, typed-array output)
// ============================================================================

const CGR_MAX_GRID_BYTES: usize = 32 * 1024 * 1024;

#[wasm_bindgen]
pub struct CgrCountsResult {
    counts: Vec<u32>,
    resolution: usize,
    k: u32,
    max_count: u32,
    total_points: u32,
    entropy: f64,
}

#[wasm_bindgen]
impl CgrCountsResult {
    #[wasm_bindgen(getter)]
    pub fn counts(&self) -> js_sys::Uint32Array {
        let arr = js_sys::Uint32Array::new_with_length(self.counts.len() as u32);
        arr.copy_from(&self.counts);
        arr
    }

    #[wasm_bindgen(getter)]
    pub fn resolution(&self) -> usize {
        self.resolution
    }

    #[wasm_bindgen(getter)]
    pub fn k(&self) -> u32 {
        self.k
    }

    #[wasm_bindgen(getter)]
    pub fn max_count(&self) -> u32 {
        self.max_count
    }

    #[wasm_bindgen(getter)]
    pub fn total_points(&self) -> u32 {
        self.total_points
    }

    #[wasm_bindgen(getter)]
    pub fn entropy(&self) -> f64 {
        self.entropy
    }
}

/// Compute Chaos Game Representation (CGR) counts for a sequence.
///
/// Semantics match `packages/core/src/analysis/cgr.ts`:
/// - Non-ACGT characters are skipped (no state update).
/// - "Transient removal" uses the raw index: we only start plotting after `i >= k-1`,
///   where `i` is the index in the *original* input (including skipped chars).
///
/// # Inputs
/// - `seq_bytes`: ASCII DNA/RNA bytes OR already-encoded ACGT05 (0..=4).
/// - `k`: CGR depth (resolution = 2^k). k=0 yields a 1x1 grid.
///
/// # Outputs
/// - Dense grid counts as `Uint32Array` (row-major, length = resolution*resolution)
/// - Metadata: resolution, max_count, total_points, entropy (Shannon, base2)
#[wasm_bindgen]
pub fn cgr_counts(seq_bytes: &[u8], k: u32) -> CgrCountsResult {
    let resolution = if k == 0 {
        1usize
    } else {
        match 1usize.checked_shl(k) {
            Some(v) => v,
            None => {
                return CgrCountsResult {
                    counts: Vec::new(),
                    resolution: 0,
                    k,
                    max_count: 0,
                    total_points: 0,
                    entropy: 0.0,
                }
            }
        }
    };

    let cells = match resolution.checked_mul(resolution) {
        Some(v) => v,
        None => {
            return CgrCountsResult {
                counts: Vec::new(),
                resolution: 0,
                k,
                max_count: 0,
                total_points: 0,
                entropy: 0.0,
            }
        }
    };

    let bytes_needed = match cells.checked_mul(std::mem::size_of::<u32>()) {
        Some(v) => v,
        None => usize::MAX,
    };
    if bytes_needed > CGR_MAX_GRID_BYTES {
        return CgrCountsResult {
            counts: Vec::new(),
            resolution: 0,
            k,
            max_count: 0,
            total_points: 0,
            entropy: 0.0,
        };
    }

    let mut counts = vec![0u32; cells];
    let mut max_count: u32 = 0;
    let mut total_points: u32 = 0;

    if seq_bytes.is_empty() {
        return CgrCountsResult {
            counts,
            resolution,
            k,
            max_count,
            total_points,
            entropy: 0.0,
        };
    }

    if k == 0 {
        // With resolution=1, all points land in cell 0.
        for &raw in seq_bytes {
            let code = if raw <= 4 { raw } else { encode_base(raw) };
            if code <= 3 {
                counts[0] = counts[0].saturating_add(1);
                total_points = total_points.saturating_add(1);
                max_count = counts[0];
            }
        }

        // Entropy is always 0 for a 1-cell distribution.
        return CgrCountsResult {
            counts,
            resolution,
            k,
            max_count,
            total_points,
            entropy: 0.0,
        };
    }

    // Fixed-point top-k-bit register with initial x=y=0.5.
    // Start bits: 1000...0 (k bits) so floor(0.5 * 2^k) == 2^(k-1).
    let shift = (k - 1) as u32;
    let init = 1u32 << shift;
    let mut x_bits: u32 = init;
    let mut y_bits: u32 = init;

    for (i, &raw) in seq_bytes.iter().enumerate() {
        let code = if raw <= 4 { raw } else { encode_base(raw) };
        if code > 3 {
            continue;
        }

        // A=0, C=1, G=2, T=3.
        // X: right half for T/G; Y: bottom half for C/G.
        let bit_x: u32 = if code == SEQ_BASE_G || code == SEQ_BASE_T { 1 } else { 0 };
        let bit_y: u32 = if code == SEQ_BASE_C || code == SEQ_BASE_G { 1 } else { 0 };

        x_bits = (x_bits >> 1) | (bit_x << shift);
        y_bits = (y_bits >> 1) | (bit_y << shift);

        if i < (k as usize).saturating_sub(1) {
            continue;
        }

        let gx = x_bits as usize;
        let gy = y_bits as usize;
        let idx = gy * resolution + gx;

        let next = counts[idx].saturating_add(1);
        counts[idx] = next;
        total_points = total_points.saturating_add(1);
        if next > max_count {
            max_count = next;
        }
    }

    let mut entropy = 0.0f64;
    if total_points > 0 {
        let denom = total_points as f64;
        for &c in &counts {
            if c == 0 {
                continue;
            }
            let p = (c as f64) / denom;
            entropy -= p * p.log2();
        }
        if entropy < 0.0 {
            entropy = 0.0;
        }
    }

    CgrCountsResult {
        counts,
        resolution,
        k,
        max_count,
        total_points,
        entropy,
    }
}

#[cfg(test)]
mod hilbert_tests {
    use super::*;

    #[test]
    fn hilbert_rgba_maps_first_points_and_background() {
        // Packed RGB palette for [A,C,G,T,N]
        let colors: Vec<u8> = vec![
            1, 2, 3,    // A
            4, 5, 6,    // C
            7, 8, 9,    // G
            10, 11, 12, // T
            13, 14, 15, // N (background)
        ];

        let out = hilbert_rgba(b"ACGT", 4, &colors);
        assert_eq!(out.len(), 16 * 16 * 4);

        // d=0 => (0,0): A
        assert_eq!(&out[0..4], &[1, 2, 3, 255]);
        // d=1 => (1,0): C
        assert_eq!(&out[4..8], &[4, 5, 6, 255]);
        // d=2 => (1,1): G
        assert_eq!(&out[68..72], &[7, 8, 9, 255]);
        // d=3 => (0,1): T
        assert_eq!(&out[64..68], &[10, 11, 12, 255]);

        // Ensure unused pixels remain background (N).
        // Pixel (0,2) is not painted for seq length 4.
        assert_eq!(&out[128..132], &[13, 14, 15, 255]);
    }
}

#[cfg(test)]
mod cgr_tests {
    use super::*;

    #[test]
    fn cgr_counts_empty_sequence_matches_js_semantics() {
        let r = cgr_counts(b"", 2);
        assert_eq!(r.resolution, 4);
        assert_eq!(r.total_points, 0);
        assert_eq!(r.max_count, 0);
        assert!((r.entropy - 0.0).abs() < 1e-12);
        assert_eq!(r.counts.len(), 16);
        assert!(r.counts.iter().all(|&v| v == 0));
    }

    #[test]
    fn cgr_counts_transient_removal_matches_js_semantics() {
        // Mirrors `packages/core/src/analysis/cgr.test.ts`.
        let seq = b"AAAAAA";
        let k = 3;
        let r = cgr_counts(seq, k);
        assert_eq!(r.total_points, (seq.len() as u32).saturating_sub((k - 1) as u32));
        assert_eq!(r.max_count, r.total_points);
    }

    #[test]
    fn cgr_counts_skips_non_acgt_characters() {
        let r = cgr_counts(b"ANNT", 1);
        assert_eq!(r.total_points, 2);
    }
}

// ============================================================================
// Grid Building - HOT PATH for viewport rendering
// ============================================================================

/// Result of grid building for sequence viewport
#[wasm_bindgen]
pub struct GridResult {
    /// JSON-encoded grid data
    json: String,
}

#[wasm_bindgen]
impl GridResult {
    #[wasm_bindgen(getter)]
    pub fn json(&self) -> String {
        self.json.clone()
    }
}

// ============================================================================
// Spatial-Hash Bond Detection - O(N) algorithm for molecular structure
// ============================================================================

/// Element covalent radii in Angstroms for bond detection
/// Matches the JavaScript implementation exactly for consistency
const fn element_radius(element: u8) -> f32 {
    match element {
        b'H' => 0.31,
        b'C' => 0.76,
        b'N' => 0.71,
        b'O' => 0.66,
        b'S' => 1.05,
        b'P' => 1.07,
        _ => 0.80, // Default for unknown elements
    }
}

/// Maximum possible bond distance: (1.07 + 1.07) * 1.25 = 2.675 Ã
/// We use 2.7 Ã as the cell size for the spatial hash
const CELL_SIZE: f32 = 2.7;
const BOND_TOLERANCE: f32 = 1.25;

/// Result of bond detection
#[wasm_bindgen]
pub struct BondDetectionResult {
    /// Flat array of bond pairs: [a0, b0, a1, b1, ...]
    /// Each pair (a, b) represents a bond between atom indices a and b
    bonds: Vec<u32>,
    /// Number of bonds found
    bond_count: usize,
}

#[wasm_bindgen]
impl BondDetectionResult {
    /// Get bonds as flat array [a0, b0, a1, b1, ...]
    #[wasm_bindgen(getter)]
    pub fn bonds(&self) -> Vec<u32> {
        self.bonds.clone()
    }

    /// Get the number of bonds
    #[wasm_bindgen(getter)]
    pub fn bond_count(&self) -> usize {
        self.bond_count
    }
}

/// Spatial hash grid for O(1) neighbor lookups
struct SpatialHash {
    cells: HashMap<(i32, i32, i32), Vec<usize>>,
    cell_size: f32,
}

impl SpatialHash {
    fn new(cell_size: f32) -> Self {
        SpatialHash {
            cells: HashMap::new(),
            cell_size,
        }
    }

    #[inline]
    fn cell_coords(&self, x: f32, y: f32, z: f32) -> (i32, i32, i32) {
        (
            (x / self.cell_size).floor() as i32,
            (y / self.cell_size).floor() as i32,
            (z / self.cell_size).floor() as i32,
        )
    }

    fn insert(&mut self, idx: usize, x: f32, y: f32, z: f32) {
        let coords = self.cell_coords(x, y, z);
        self.cells.entry(coords).or_insert_with(Vec::new).push(idx);
    }

    /// Get indices of atoms in the same and neighboring cells (27 cells total)
    fn get_neighbors(&self, x: f32, y: f32, z: f32) -> impl Iterator<Item = usize> + '_ {
        let (cx, cy, cz) = self.cell_coords(x, y, z);

        // Iterate over 3x3x3 neighboring cells
        (-1..=1).flat_map(move |dx| {
            (-1..=1).flat_map(move |dy| {
                (-1..=1).flat_map(move |dz| {
                    self.cells
                        .get(&(cx + dx, cy + dy, cz + dz))
                        .map(|v| v.iter().copied())
                        .into_iter()
                        .flatten()
                })
            })
        })
    }
}

/// Detect bonds using spatial hashing for O(N) complexity.
///
/// This is the CRITICAL optimization replacing the O(NÂ²) algorithm.
/// For a 50,000 atom structure:
/// - Old: 1.25 billion comparisons â 30-60+ seconds
/// - New: ~1 million comparisons â <1 second
///
/// # Arguments
/// * `positions` - Flat array of atom positions [x0, y0, z0, x1, y1, z1, ...]
/// * `elements` - String of element symbols (one char per atom: "CCCCNNO...")
///
/// # Returns
/// BondDetectionResult with pairs of bonded atom indices.
///
/// # Algorithm
/// 1. Build spatial hash with cell size = max bond distance (~2.7Ã)
/// 2. For each atom, only check atoms in neighboring 27 cells
/// 3. Reduces O(NÂ²) to O(N * k) where k â 20 atoms per neighborhood
#[wasm_bindgen]
pub fn detect_bonds_spatial(positions: &[f32], elements: &str) -> BondDetectionResult {
    let num_atoms = elements.len();

    // Validate input
    if positions.len() != num_atoms * 3 {
        return BondDetectionResult {
            bonds: Vec::new(),
            bond_count: 0,
        };
    }

    if num_atoms == 0 {
        return BondDetectionResult {
            bonds: Vec::new(),
            bond_count: 0,
        };
    }

    let element_bytes = elements.as_bytes();

    // Build spatial hash
    let mut grid = SpatialHash::new(CELL_SIZE);
    for i in 0..num_atoms {
        let x = positions[i * 3];
        let y = positions[i * 3 + 1];
        let z = positions[i * 3 + 2];
        grid.insert(i, x, y, z);
    }

    // Detect bonds using spatial hash
    let mut bonds = Vec::with_capacity(num_atoms * 4); // Estimate ~4 bonds per atom

    for i in 0..num_atoms {
        let x1 = positions[i * 3];
        let y1 = positions[i * 3 + 1];
        let z1 = positions[i * 3 + 2];
        let r1 = element_radius(element_bytes[i]);

        // Only check neighboring cells
        for j in grid.get_neighbors(x1, y1, z1) {
            // Only check j > i to avoid duplicate bonds
            if j <= i {
                continue;
            }

            let x2 = positions[j * 3];
            let y2 = positions[j * 3 + 1];
            let z2 = positions[j * 3 + 2];

            let dx = x1 - x2;
            let dy = y1 - y2;
            let dz = z1 - z2;
            let dist_sq = dx * dx + dy * dy + dz * dz;

            let r2 = element_radius(element_bytes[j]);
            let threshold = (r1 + r2) * BOND_TOLERANCE;
            let threshold_sq = threshold * threshold;

            if dist_sq <= threshold_sq {
                bonds.push(i as u32);
                bonds.push(j as u32);
            }
        }
    }

    let bond_count = bonds.len() / 2;
    BondDetectionResult { bonds, bond_count }
}

// ============================================================================
// Functional Group Detection - WASM-accelerated for large structures
// ============================================================================

/// Result of functional group detection.
/// Contains flat arrays of atom indices for each functional group type.
#[wasm_bindgen]
pub struct FunctionalGroupResult {
    /// Flat array of aromatic ring atom indices.
    /// Rings are separated by the ring_sizes array.
    aromatic_indices: Vec<u32>,
    /// Number of atoms in each aromatic ring (all should be 6 for 6-membered rings).
    ring_sizes: Vec<u32>,
    /// Disulfide bond pairs: [s1, s2, s1, s2, ...].
    disulfide_pairs: Vec<u32>,
    /// Phosphate group data: for each group [p_idx, num_oxygens, o1, o2, o3, ...].
    phosphate_data: Vec<u32>,
    /// Number of aromatic rings found.
    aromatic_count: usize,
    /// Number of disulfide bonds found.
    disulfide_count: usize,
    /// Number of phosphate groups found.
    phosphate_count: usize,
}

#[wasm_bindgen]
impl FunctionalGroupResult {
    /// Get aromatic ring atom indices as flat array.
    #[wasm_bindgen(getter)]
    pub fn aromatic_indices(&self) -> Vec<u32> {
        self.aromatic_indices.clone()
    }

    /// Get sizes of each aromatic ring.
    #[wasm_bindgen(getter)]
    pub fn ring_sizes(&self) -> Vec<u32> {
        self.ring_sizes.clone()
    }

    /// Get disulfide bond pairs as flat array [s1, s2, s1, s2, ...].
    #[wasm_bindgen(getter)]
    pub fn disulfide_pairs(&self) -> Vec<u32> {
        self.disulfide_pairs.clone()
    }

    /// Get phosphate group data.
    #[wasm_bindgen(getter)]
    pub fn phosphate_data(&self) -> Vec<u32> {
        self.phosphate_data.clone()
    }

    /// Number of aromatic rings.
    #[wasm_bindgen(getter)]
    pub fn aromatic_count(&self) -> usize {
        self.aromatic_count
    }

    /// Number of disulfide bonds.
    #[wasm_bindgen(getter)]
    pub fn disulfide_count(&self) -> usize {
        self.disulfide_count
    }

    /// Number of phosphate groups.
    #[wasm_bindgen(getter)]
    pub fn phosphate_count(&self) -> usize {
        self.phosphate_count
    }
}

/// Build adjacency list from bond pairs.
fn build_adjacency(num_atoms: usize, bonds: &[u32]) -> Vec<Vec<usize>> {
    let mut adj: Vec<Vec<usize>> = vec![Vec::new(); num_atoms];
    for chunk in bonds.chunks(2) {
        if chunk.len() == 2 {
            let a = chunk[0] as usize;
            let b = chunk[1] as usize;
            if a < num_atoms && b < num_atoms {
                adj[a].push(b);
                adj[b].push(a);
            }
        }
    }
    adj
}

/// Check if a ring is planar within a tolerance.
fn is_planar_ring(indices: &[usize], positions: &[f32], tolerance: f32) -> bool {
    if indices.len() < 3 {
        return false;
    }

    // Get first three points to define a plane
    let (i0, i1, i2) = (indices[0], indices[1], indices[2]);
    let ax = positions[i0 * 3];
    let ay = positions[i0 * 3 + 1];
    let az = positions[i0 * 3 + 2];
    let bx = positions[i1 * 3];
    let by = positions[i1 * 3 + 1];
    let bz = positions[i1 * 3 + 2];
    let cx = positions[i2 * 3];
    let cy = positions[i2 * 3 + 1];
    let cz = positions[i2 * 3 + 2];

    // Vectors from A to B and A to C
    let v1x = bx - ax;
    let v1y = by - ay;
    let v1z = bz - az;
    let v2x = cx - ax;
    let v2y = cy - ay;
    let v2z = cz - az;

    // Cross product for normal
    let mut nx = v1y * v2z - v1z * v2y;
    let mut ny = v1z * v2x - v1x * v2z;
    let mut nz = v1x * v2y - v1y * v2x;

    // Normalize
    let len = (nx * nx + ny * ny + nz * nz).sqrt();
    if len == 0.0 {
        return false;
    }
    nx /= len;
    ny /= len;
    nz /= len;

    // Check distance to plane for all atoms
    for &idx in indices {
        let px = positions[idx * 3];
        let py = positions[idx * 3 + 1];
        let pz = positions[idx * 3 + 2];
        let dist = (nx * (px - ax) + ny * (py - ay) + nz * (pz - az)).abs();
        if dist > tolerance {
            return false;
        }
    }
    true
}

/// Detect 6-membered aromatic rings (benzene-like).
/// Uses DFS to find cycles of exactly 6 carbon atoms.
fn detect_aromatic_rings(
    positions: &[f32],
    element_bytes: &[u8],
    adj: &[Vec<usize>],
    num_atoms: usize,
) -> (Vec<u32>, Vec<u32>) {
    let mut aromatic_indices = Vec::new();
    let mut ring_sizes = Vec::new();
    let max_planar_offset = 0.25_f32;

    let is_carbon = |idx: usize| -> bool {
        idx < element_bytes.len() && (element_bytes[idx] == b'C' || element_bytes[idx] == b'c')
    };

    // For each carbon atom, try to find 6-membered rings
    for start in 0..num_atoms {
        if !is_carbon(start) {
            continue;
        }

        // DFS to find 6-cycles starting from this atom
        let mut stack: Vec<(usize, usize, Vec<usize>)> = vec![(start, 0, vec![start])];

        while let Some((current, depth, path)) = stack.pop() {
            if depth == 5 {
                // Check if we can close back to start
                for &next in &adj[current] {
                    if next == start {
                        // Found a 6-cycle
                        // Skip if any atom has index < start (to avoid duplicates)
                        if path.iter().any(|&idx| idx < start) {
                            continue;
                        }
                        // Check all atoms are carbon
                        if !path.iter().all(|&idx| is_carbon(idx)) {
                            continue;
                        }
                        // Check planarity
                        if is_planar_ring(&path, positions, max_planar_offset) {
                            for &idx in &path {
                                aromatic_indices.push(idx as u32);
                            }
                            ring_sizes.push(6);
                        }
                    }
                }
                continue;
            }

            // Explore neighbors
            for &next in &adj[current] {
                if next == start && depth < 4 {
                    continue; // Too early to close
                }
                if next <= start {
                    continue; // Only explore forward to avoid duplicates
                }
                if path.contains(&next) {
                    continue; // Already in path
                }

                let mut new_path = path.clone();
                new_path.push(next);
                stack.push((next, depth + 1, new_path));
            }
        }
    }

    (aromatic_indices, ring_sizes)
}

/// Detect disulfide bonds (S-S bonds).
/// Either directly bonded or within 2.2 Ã distance.
fn detect_disulfides(
    positions: &[f32],
    element_bytes: &[u8],
    adj: &[Vec<usize>],
    num_atoms: usize,
) -> Vec<u32> {
    let mut disulfide_pairs = Vec::new();
    let max_ss_dist_sq = 2.2_f32 * 2.2_f32;

    // Find all sulfur atoms
    let sulfur_indices: Vec<usize> = (0..num_atoms)
        .filter(|&i| i < element_bytes.len() && (element_bytes[i] == b'S' || element_bytes[i] == b's'))
        .collect();

    // Check pairs of sulfurs
    for i in 0..sulfur_indices.len() {
        for j in (i + 1)..sulfur_indices.len() {
            let a = sulfur_indices[i];
            let b = sulfur_indices[j];

            // Check if directly bonded
            let bonded = adj[a].contains(&b);

            // Check distance
            let dx = positions[a * 3] - positions[b * 3];
            let dy = positions[a * 3 + 1] - positions[b * 3 + 1];
            let dz = positions[a * 3 + 2] - positions[b * 3 + 2];
            let dist_sq = dx * dx + dy * dy + dz * dz;

            if bonded || dist_sq <= max_ss_dist_sq {
                disulfide_pairs.push(a as u32);
                disulfide_pairs.push(b as u32);
            }
        }
    }

    disulfide_pairs
}

/// Detect phosphate groups (P with 3+ oxygen neighbors).
fn detect_phosphates(
    element_bytes: &[u8],
    adj: &[Vec<usize>],
    num_atoms: usize,
) -> Vec<u32> {
    let mut phosphate_data = Vec::new();

    for idx in 0..num_atoms {
        // Check if phosphorus
        if idx >= element_bytes.len() {
            continue;
        }
        if element_bytes[idx] != b'P' && element_bytes[idx] != b'p' {
            continue;
        }

        // Find oxygen neighbors
        let oxygen_neighbors: Vec<usize> = adj[idx]
            .iter()
            .filter(|&&n| {
                n < element_bytes.len() && (element_bytes[n] == b'O' || element_bytes[n] == b'o')
            })
            .copied()
            .collect();

        if oxygen_neighbors.len() >= 3 {
            // Store: [p_idx, num_oxygens, o1, o2, o3, ...]
            phosphate_data.push(idx as u32);
            phosphate_data.push(oxygen_neighbors.len() as u32);
            for &o_idx in &oxygen_neighbors {
                phosphate_data.push(o_idx as u32);
            }
        }
    }

    phosphate_data
}

/// Detect functional groups (aromatic rings, disulfides, phosphates) using WASM.
///
/// This replaces the O(NÂ²) JavaScript implementation with an optimized Rust version.
/// The adjacency list is built once and reused for all detection algorithms.
///
/// # Arguments
/// * `positions` - Flat array of atom positions [x0, y0, z0, x1, y1, z1, ...]
/// * `elements` - String of element symbols (one char per atom: "CCCCNNO...")
/// * `bonds` - Flat array of bond pairs [a0, b0, a1, b1, ...] from detect_bonds_spatial
///
/// # Returns
/// FunctionalGroupResult with typed arrays for each group type.
#[wasm_bindgen]
pub fn detect_functional_groups(
    positions: &[f32],
    elements: &str,
    bonds: &[u32],
) -> FunctionalGroupResult {
    let num_atoms = elements.len();

    // Validate input
    if positions.len() != num_atoms * 3 || num_atoms == 0 {
        return FunctionalGroupResult {
            aromatic_indices: Vec::new(),
            ring_sizes: Vec::new(),
            disulfide_pairs: Vec::new(),
            phosphate_data: Vec::new(),
            aromatic_count: 0,
            disulfide_count: 0,
            phosphate_count: 0,
        };
    }

    let element_bytes = elements.as_bytes();

    // Build adjacency list once
    let adj = build_adjacency(num_atoms, bonds);

    // Detect all functional groups
    let (aromatic_indices, ring_sizes) =
        detect_aromatic_rings(positions, element_bytes, &adj, num_atoms);
    let disulfide_pairs = detect_disulfides(positions, element_bytes, &adj, num_atoms);
    let phosphate_data = detect_phosphates(element_bytes, &adj, num_atoms);

    // Count groups
    let aromatic_count = ring_sizes.len();
    let disulfide_count = disulfide_pairs.len() / 2;

    // Count phosphate groups by parsing phosphate_data
    let mut phosphate_count = 0;
    let mut i = 0;
    while i < phosphate_data.len() {
        phosphate_count += 1;
        if i + 1 < phosphate_data.len() {
            let num_oxygens = phosphate_data[i + 1] as usize;
            i += 2 + num_oxygens;
        } else {
            break;
        }
    }

    FunctionalGroupResult {
        aromatic_indices,
        ring_sizes,
        disulfide_pairs,
        phosphate_data,
        aromatic_count,
        disulfide_count,
        phosphate_count,
    }
}

// ============================================================================
// Grid Building - HOT PATH for viewport rendering
// ============================================================================

/// Build a grid of sequence data for viewport rendering.
///
/// This is the HOT PATH called on every scroll. Optimized for minimal
/// allocations and fast character processing.
///
/// # Arguments
/// * `seq` - Full sequence string
/// * `start_index` - Starting position in sequence (0-based)
/// * `cols` - Number of columns in grid
/// * `rows` - Number of rows in grid
/// * `mode` - Display mode: "dna", "aa", or "dual"
/// * `frame` - Reading frame for AA translation (0, 1, or 2)
///
/// # Returns
/// GridResult with JSON-encoded rows, each containing:
/// - cells: array of {char, phase, is_stop, is_start} for DNA mode
/// - cells: array of {char, codon, is_stop, is_start} for AA mode
#[wasm_bindgen]
pub fn build_grid(
    seq: &str,
    start_index: usize,
    cols: usize,
    rows: usize,
    mode: &str,
    frame: i8,
) -> GridResult {
    let bytes = seq.as_bytes();
    let n = bytes.len();

    if cols == 0 || rows == 0 || start_index >= n {
        return GridResult { json: "[]".to_string() };
    }

    let frame = frame.rem_euclid(3) as usize;
    let mode_is_aa = mode == "aa";
    let _mode_is_dual = mode == "dual"; // Reserved for future dual-view support

    let mut result_rows: Vec<String> = Vec::with_capacity(rows);

    for row in 0..rows {
        let row_start = start_index + row * cols;
        if row_start >= n {
            break;
        }

        let row_end = (row_start + cols).min(n);
        let mut cells: Vec<String> = Vec::with_capacity(cols);

        if mode_is_aa {
            // Amino acid mode: translate codons
            let mut i = row_start;
            // Adjust to codon boundary
            let offset = (i as i64 - frame as i64).rem_euclid(3) as usize;
            if offset != 0 {
                i += 3 - offset;
            }

            while i + 3 <= row_end && i + 3 <= n {
                let aa = codon_to_aa(bytes[i], bytes[i + 1], bytes[i + 2]);
                let codon: String = bytes[i..i + 3]
                    .iter()
                    .map(|&b| (b as char).to_ascii_uppercase())
                    .collect();

                let is_stop = aa == b'*';
                let is_start = aa == b'M';

                cells.push(format!(
                    "{{\"char\":\"{}\",\"codon\":\"{}\",\"pos\":{},\"is_stop\":{},\"is_start\":{}}}",
                    aa as char, codon, i, is_stop, is_start
                ));

                i += 3;
            }
        } else {
            // DNA mode (or dual)
            for i in row_start..row_end {
                let base = bytes[i];
                let char_upper = (base as char).to_ascii_uppercase();

                // Calculate codon phase (position within codon)
                let phase = ((i as i64 - frame as i64).rem_euclid(3)) as u8;

                // Check if this position starts a stop or start codon
                let (is_stop, is_start) = if phase == 0 && i + 3 <= n {
                    let aa = codon_to_aa(bytes[i], bytes[i + 1], bytes[i + 2]);
                    (aa == b'*', aa == b'M')
                } else {
                    (false, false)
                };

                cells.push(format!(
                    "{{\"char\":\"{}\",\"pos\":{},\"phase\":{},\"is_stop\":{},\"is_start\":{}}}",
                    char_upper, i, phase, is_stop, is_start
                ));
            }
        }

        let row_json = format!(
            "{{\"row\":{},\"start\":{},\"end\":{},\"cells\":[{}]}}",
            row,
            row_start,
            row_end,
            cells.join(",")
        );
        result_rows.push(row_json);
    }

    GridResult {
        json: format!("[{}]", result_rows.join(",")),
    }
}

// ============================================================================
// Sequence Rendering Optimizations (Hot Path)
// ============================================================================
//
// STATUS: NOT CURRENTLY WIRED IN
//
// These functions were written as potential WASM optimizations for
// CanvasSequenceGridRenderer.ts, but are NOT currently used. The JS
// implementation was already optimized with single-pass run-length encoding
// algorithms that achieve 60fps rendering.
//
// Why not wired in:
// 1. The JS implementation is already efficient (single-pass, typed arrays)
// 2. WASM boundary overhead (data copying, async loading) may negate gains
// 3. For typical genome sizes (50-300kb), JS renders in <3ms per frame
// 4. Adding optional WASM loading adds complexity without clear benefit
//
// When to consider wiring in:
// - If profiling shows renderMicroBatch is a bottleneck (>8ms/frame)
// - For very large sequences (>1MB) where WASM's tighter loops help
// - If we add multi-threaded rendering via Web Workers + SharedArrayBuffer
//
// To wire in: Add optional WASM loading in CanvasSequenceGridRenderer.ts
// and call these functions instead of the JS equivalents when available.
//
// See: packages/web/src/rendering/CanvasSequenceGridRenderer.ts
//      - encodeSequence() at line ~33 (JS equivalent of encode_sequence_fast)
//      - renderMicroBatch() at line ~833 (JS equivalent of compute_micro_runs)
// ============================================================================

/// Fast sequence encoding for canvas rendering.
///
/// **STATUS: NOT WIRED IN** - JS `encodeSequence()` is used instead.
/// Kept for future optimization if profiling shows encoding is a bottleneck.
///
/// Encodes nucleotide characters to numeric codes:
/// - A/a -> 0, C/c -> 1, G/g -> 2, T/t/U/u -> 3, other -> 4 (N)
///
/// This would be used by CanvasSequenceGridRenderer for O(1) lookups during rendering.
/// WASM version is ~4x faster than JS for large sequences due to tighter loops,
/// but encoding only happens once per sequence change (not per frame).
///
/// # Arguments
/// * `seq` - DNA/RNA sequence string
///
/// # Returns
/// Uint8Array with encoded values (0-4)
#[wasm_bindgen]
pub fn encode_sequence_fast(seq: &str) -> Vec<u8> {
    let bytes = seq.as_bytes();
    let mut encoded = Vec::with_capacity(bytes.len());

    for &b in bytes {
        let code = match b {
            b'A' | b'a' => 0,
            b'C' | b'c' => 1,
            b'G' | b'g' => 2,
            b'T' | b't' | b'U' | b'u' => 3,
            _ => 4, // N or other
        };
        encoded.push(code);
    }

    encoded
}

/// Compute color runs for micro batch rendering.
///
/// **STATUS: NOT WIRED IN** - JS `renderMicroBatch()` is used instead.
/// Kept for future optimization if profiling shows rendering is a bottleneck.
/// The JS version already uses the same single-pass algorithm and achieves 60fps.
///
/// This performs single-pass run-length encoding on an encoded sequence,
/// producing runs grouped by color. The output is a flat Float32Array where
/// every 4 values represent: [color_code, row_y, x, width].
///
/// Runs are sorted by color so the JS renderer only needs 5 fillStyle changes.
///
/// # Arguments
/// * `encoded` - Pre-encoded sequence (values 0-4)
/// * `start_row` - First visible row index
/// * `end_row` - Last visible row index (exclusive)
/// * `cols` - Number of columns per row
/// * `cell_width` - Width of each cell in pixels
/// * `cell_height` - Height of each cell in pixels
/// * `offset_y` - Y offset for first visible row (sub-pixel scrolling)
/// * `start_row_offset` - startRow value from visible range (for row Y calculation)
///
/// # Returns
/// Float32Array with runs: [color, y, x, width, color, y, x, width, ...]
/// First value is the total number of runs.
#[wasm_bindgen]
pub fn compute_micro_runs(
    encoded: &[u8],
    start_row: u32,
    end_row: u32,
    cols: u32,
    cell_width: f32,
    cell_height: f32,
    offset_y: f32,
    start_row_offset: u32,
) -> Vec<f32> {
    // Pre-allocate for typical case (estimate ~1 run per 5 cells due to compression)
    let estimated_runs = ((end_row - start_row) as usize * cols as usize) / 5;

    // Store runs grouped by color (5 vectors)
    let mut runs_by_color: [Vec<[f32; 3]>; 5] = Default::default();
    for color_runs in &mut runs_by_color {
        color_runs.reserve(estimated_runs / 5);
    }

    let seq_len = encoded.len() as u32;

    for row in start_row..end_row {
        let row_start = row * cols;
        if row_start >= seq_len {
            break;
        }
        let row_end = ((row + 1) * cols).min(seq_len);

        let row_y = (row - start_row_offset) as f32 * cell_height + offset_y;

        // Get first cell's color
        let first_idx = row_start as usize;
        if first_idx >= encoded.len() {
            break;
        }

        let mut run_code = encoded[first_idx];
        let mut run_start_col: u32 = 0;

        for i in (row_start + 1)..row_end {
            let idx = i as usize;
            if idx >= encoded.len() {
                break;
            }
            let code = encoded[idx];
            if code != run_code {
                // End current run
                let col = i - row_start;
                let x = run_start_col as f32 * cell_width;
                let width = (col - run_start_col) as f32 * cell_width;
                if run_code < 5 {
                    runs_by_color[run_code as usize].push([row_y, x, width]);
                }
                run_code = code;
                run_start_col = col;
            }
        }

        // Final run in row
        let final_col = row_end - row_start;
        if final_col > run_start_col && run_code < 5 {
            let x = run_start_col as f32 * cell_width;
            let width = (final_col - run_start_col) as f32 * cell_width;
            runs_by_color[run_code as usize].push([row_y, x, width]);
        }
    }

    // Count total runs
    let total_runs: usize = runs_by_color.iter().map(|v| v.len()).sum();

    // Output format: [total_runs, color0_count, color1_count, ..., color4_count, then all runs]
    // Each run: [y, x, width] (color is implicit from position)
    let mut result = Vec::with_capacity(6 + total_runs * 3);

    // Header: total runs + count per color
    result.push(total_runs as f32);
    for color_runs in &runs_by_color {
        result.push(color_runs.len() as f32);
    }

    // Runs grouped by color
    for color_runs in &runs_by_color {
        for run in color_runs {
            result.push(run[0]); // y
            result.push(run[1]); // x
            result.push(run[2]); // width
        }
    }

    result
}

/// Compute diff mask between two sequences.
///
/// **STATUS: NOT WIRED IN** - Diff computation happens in JS.
/// Kept for future optimization if diff mode becomes a performance concern.
/// Diff is computed once per sequence change, not per frame, so JS is adequate.
///
/// Compares a query sequence against a reference sequence and produces
/// a diff mask indicating the type of difference at each position:
/// - 0: Match
/// - 1: Mismatch (substitution)
/// - 2: Insertion (in query relative to ref - not computed here, placeholder)
/// - 3: Deletion (in query relative to ref - not computed here, placeholder)
///
/// For simple pairwise comparison without alignment, only 0 and 1 are used.
///
/// # Arguments
/// * `query` - Query sequence (the one being displayed)
/// * `reference` - Reference sequence to compare against
///
/// # Returns
/// Uint8Array with diff codes (0 = match, 1 = mismatch)
#[wasm_bindgen]
pub fn compute_diff_mask(query: &str, reference: &str) -> Vec<u8> {
    let query_bytes = query.as_bytes();
    let ref_bytes = reference.as_bytes();
    let len = query_bytes.len();

    let mut mask = vec![0u8; len];

    // Compare character by character (case-insensitive)
    let ref_len = ref_bytes.len();
    for i in 0..len {
        if i < ref_len {
            let q = query_bytes[i].to_ascii_uppercase();
            let r = ref_bytes[i].to_ascii_uppercase();
            if q != r {
                mask[i] = 1; // Mismatch
            }
        } else {
            // Query extends beyond reference
            mask[i] = 1;
        }
    }

    mask
}

/// Compute diff mask from pre-encoded sequences (faster than string version).
///
/// **STATUS: NOT WIRED IN** - See `compute_diff_mask` above.
/// This is the faster variant that operates on pre-encoded sequences.
///
/// # Arguments
/// * `query_encoded` - Pre-encoded query sequence (values 0-4)
/// * `ref_encoded` - Pre-encoded reference sequence (values 0-4)
///
/// # Returns
/// Uint8Array with diff codes (0 = match, 1 = mismatch)
#[wasm_bindgen]
pub fn compute_diff_mask_encoded(query_encoded: &[u8], ref_encoded: &[u8]) -> Vec<u8> {
    let len = query_encoded.len();
    let ref_len = ref_encoded.len();

    let mut mask = vec![0u8; len];

    for i in 0..len {
        if i < ref_len {
            if query_encoded[i] != ref_encoded[i] {
                mask[i] = 1;
            }
        } else {
            mask[i] = 1;
        }
    }

    mask
}

// ============================================================================
// KL Divergence for Anomaly Detection
// ============================================================================

/// Compute Kullback-Leibler divergence between two dense k-mer count arrays.
///
/// D_KL(P || Q) = sum(P(i) * log2(P(i) / Q(i)))
///
/// Both arrays are normalized internally to probability distributions.
/// Missing k-mers in Q are smoothed with epsilon to avoid log(0).
///
/// # Arguments
/// * `p_counts` - Dense count array for distribution P (window)
/// * `q_counts` - Dense count array for distribution Q (background)
///
/// # Returns
/// KL divergence value (non-negative). Returns 0.0 if inputs are invalid.
///
/// # Note
/// Arrays must be the same length. For k-mer analysis, length should be 4^k.
///
/// @see phage_explorer-vk7b.5
#[wasm_bindgen]
pub fn kl_divergence_dense(p_counts: &[u32], q_counts: &[u32]) -> f64 {
    if p_counts.len() != q_counts.len() || p_counts.is_empty() {
        return 0.0;
    }

    // Calculate totals for normalization
    let p_total: u64 = p_counts.iter().map(|&c| c as u64).sum();
    let q_total: u64 = q_counts.iter().map(|&c| c as u64).sum();

    if p_total == 0 || q_total == 0 {
        return 0.0;
    }

    let p_total_f = p_total as f64;
    let q_total_f = q_total as f64;
    let epsilon = 1e-10; // Smoothing for zero counts in Q

    let mut kl = 0.0;

    for i in 0..p_counts.len() {
        let p_val = p_counts[i] as f64 / p_total_f;
        if p_val > 0.0 {
            let q_val = (q_counts[i] as f64 / q_total_f).max(epsilon);
            kl += p_val * (p_val / q_val).log2();
        }
    }

    kl.max(0.0) // Ensure non-negative due to floating point
}

/// Result of KL divergence window scan.
#[wasm_bindgen]
pub struct KLScanResult {
    /// KL divergence values for each window position
    kl_values: Vec<f32>,
    /// Window positions (start indices)
    positions: Vec<u32>,
    /// Number of windows scanned
    window_count: usize,
    /// K-mer size used
    k: usize,
}

#[wasm_bindgen]
impl KLScanResult {
    /// Get the KL divergence values as Float32Array
    #[wasm_bindgen(getter)]
    pub fn kl_values(&self) -> Vec<f32> {
        self.kl_values.clone()
    }

    /// Get the window start positions as Uint32Array
    #[wasm_bindgen(getter)]
    pub fn positions(&self) -> Vec<u32> {
        self.positions.clone()
    }

    /// Get the number of windows
    #[wasm_bindgen(getter)]
    pub fn window_count(&self) -> usize {
        self.window_count
    }

    /// Get the k-mer size used
    #[wasm_bindgen(getter)]
    pub fn k(&self) -> usize {
        self.k
    }
}

/// Scan a sequence for k-mer KL divergence anomalies.
///
/// Computes KL divergence of each sliding window against the global
/// sequence background. This is the core computation for anomaly detection.
///
/// # Arguments
/// * `seq` - Sequence bytes (ASCII DNA)
/// * `k` - K-mer size (1-10)
/// * `window_size` - Size of each window in bases
/// * `step_size` - Step size between windows
///
/// # Returns
/// `KLScanResult` with:
/// - `kl_values`: Float32Array of KL divergence for each window
/// - `positions`: Uint32Array of window start positions
/// - `window_count`: Number of windows scanned
///
/// # Performance
/// Uses dense k-mer counting for O(1) k-mer lookups.
/// Avoids string allocations by working directly with byte arrays.
///
/// # Example (from JS)
/// ```js
/// const seqBytes = new TextEncoder().encode(sequence);
/// const result = wasm.scan_kl_windows(seqBytes, 4, 500, 100);
/// try {
///   const klValues = result.kl_values; // Float32Array
///   const positions = result.positions; // Uint32Array
///   // Process anomalies...
/// } finally {
///   result.free();
/// }
/// ```
///
/// @see phage_explorer-vk7b.5
#[wasm_bindgen]
pub fn scan_kl_windows(
    seq: &[u8],
    k: usize,
    window_size: usize,
    step_size: usize,
) -> KLScanResult {
    // Validate inputs
    if k == 0 || k > DENSE_KMER_MAX_K || window_size == 0 || step_size == 0 {
        return KLScanResult {
            kl_values: Vec::new(),
            positions: Vec::new(),
            window_count: 0,
            k,
        };
    }

    if seq.len() < window_size || window_size < k {
        return KLScanResult {
            kl_values: Vec::new(),
            positions: Vec::new(),
            window_count: 0,
            k,
        };
    }

    let array_size = 1usize << (2 * k);
    let mask = array_size - 1;

    // Step 1: Compute global k-mer counts
    let mut global_counts = vec![0u32; array_size];
    let mut global_total: u64 = 0;

    {
        let mut rolling_index: usize = 0;
        let mut valid_bases: usize = 0;

        for &byte in seq {
            let base_code = match byte {
                b'A' | b'a' => 0usize,
                b'C' | b'c' => 1usize,
                b'G' | b'g' => 2usize,
                b'T' | b't' | b'U' | b'u' => 3usize,
                _ => {
                    rolling_index = 0;
                    valid_bases = 0;
                    continue;
                }
            };

            rolling_index = ((rolling_index << 2) | base_code) & mask;
            valid_bases += 1;

            if valid_bases >= k {
                global_counts[rolling_index] = global_counts[rolling_index].saturating_add(1);
                global_total += 1;
            }
        }
    }

    if global_total == 0 {
        return KLScanResult {
            kl_values: Vec::new(),
            positions: Vec::new(),
            window_count: 0,
            k,
        };
    }

    let global_total_f = global_total as f64;
    let epsilon = 1e-10;

    // Step 2: Scan sliding windows
    let mut kl_values = Vec::new();
    let mut positions = Vec::new();

    let mut pos = 0usize;
    while pos + window_size <= seq.len() {
        // Compute window k-mer counts
        let window = &seq[pos..pos + window_size];
        let mut window_counts = vec![0u32; array_size];
        let mut window_total: u64 = 0;

        let mut rolling_index: usize = 0;
        let mut valid_bases: usize = 0;

        for &byte in window {
            let base_code = match byte {
                b'A' | b'a' => 0usize,
                b'C' | b'c' => 1usize,
                b'G' | b'g' => 2usize,
                b'T' | b't' | b'U' | b'u' => 3usize,
                _ => {
                    rolling_index = 0;
                    valid_bases = 0;
                    continue;
                }
            };

            rolling_index = ((rolling_index << 2) | base_code) & mask;
            valid_bases += 1;

            if valid_bases >= k {
                window_counts[rolling_index] = window_counts[rolling_index].saturating_add(1);
                window_total += 1;
            }
        }

        // Compute KL divergence: D_KL(window || global)
        let kl = if window_total > 0 {
            let window_total_f = window_total as f64;
            let mut kl_sum = 0.0f64;

            for i in 0..array_size {
                let p_val = window_counts[i] as f64 / window_total_f;
                if p_val > 0.0 {
                    let q_val = (global_counts[i] as f64 / global_total_f).max(epsilon);
                    kl_sum += p_val * (p_val / q_val).log2();
                }
            }

            kl_sum.max(0.0) as f32
        } else {
            0.0f32
        };

        kl_values.push(kl);
        positions.push(pos as u32);

        pos += step_size;
    }

    let window_count = kl_values.len();

    KLScanResult {
        kl_values,
        positions,
        window_count,
        k,
    }
}

// ============================================================================
// Myers Diff Algorithm for DNA Sequences
// Implements O(ND) diff with compact mask encoding + summary stats
// See: phage_explorer-kyo0.1.1
// ============================================================================

/// Op codes for diff mask encoding.
/// Using small values to fit in Uint8Array efficiently.
pub const DIFF_OP_MATCH: u8 = 0;
pub const DIFF_OP_MISMATCH: u8 = 1;  // Substitution
pub const DIFF_OP_INSERT: u8 = 2;    // Present in B, not in A
pub const DIFF_OP_DELETE: u8 = 3;    // Present in A, not in B

/// Guardrails for Myers diff to prevent OOM/long runtime.
/// These can be adjusted based on profiling.
pub const DIFF_MAX_LEN: usize = 500_000;       // Max sequence length
pub const DIFF_MAX_EDIT_DISTANCE: usize = 10_000;  // Max edit distance to compute

/// Result of Myers diff computation.
///
/// # Ownership
/// The caller must call `.free()` to release WASM memory.
#[wasm_bindgen]
pub struct MyersDiffResult {
    /// Diff mask for sequence A: MATCH/MISMATCH/DELETE codes
    mask_a: Vec<u8>,
    /// Diff mask for sequence B: MATCH/MISMATCH/INSERT codes
    mask_b: Vec<u8>,
    /// Edit distance (total edits)
    edit_distance: usize,
    /// Number of matches
    matches: usize,
    /// Number of mismatches (substitutions)
    mismatches: usize,
    /// Number of insertions (in B, not in A)
    insertions: usize,
    /// Number of deletions (in A, not in B)
    deletions: usize,
    /// Whether computation was truncated due to guardrails
    truncated: bool,
    /// Error message if any
    error: Option<String>,
}

#[wasm_bindgen]
impl MyersDiffResult {
    /// Get mask for sequence A as Uint8Array.
    /// Values: 0=MATCH, 1=MISMATCH, 3=DELETE
    #[wasm_bindgen(getter)]
    pub fn mask_a(&self) -> js_sys::Uint8Array {
        let arr = js_sys::Uint8Array::new_with_length(self.mask_a.len() as u32);
        arr.copy_from(&self.mask_a);
        arr
    }

    /// Get mask for sequence B as Uint8Array.
    /// Values: 0=MATCH, 1=MISMATCH, 2=INSERT
    #[wasm_bindgen(getter)]
    pub fn mask_b(&self) -> js_sys::Uint8Array {
        let arr = js_sys::Uint8Array::new_with_length(self.mask_b.len() as u32);
        arr.copy_from(&self.mask_b);
        arr
    }

    /// Edit distance (total number of edits).
    #[wasm_bindgen(getter)]
    pub fn edit_distance(&self) -> usize {
        self.edit_distance
    }

    /// Number of matching positions.
    #[wasm_bindgen(getter)]
    pub fn matches(&self) -> usize {
        self.matches
    }

    /// Number of mismatches (substitutions).
    #[wasm_bindgen(getter)]
    pub fn mismatches(&self) -> usize {
        self.mismatches
    }

    /// Number of insertions.
    #[wasm_bindgen(getter)]
    pub fn insertions(&self) -> usize {
        self.insertions
    }

    /// Number of deletions.
    #[wasm_bindgen(getter)]
    pub fn deletions(&self) -> usize {
        self.deletions
    }

    /// Sequence identity as fraction (0.0 - 1.0).
    #[wasm_bindgen(getter)]
    pub fn identity(&self) -> f64 {
        let total = self.matches + self.mismatches + self.insertions + self.deletions;
        if total == 0 {
            1.0
        } else {
            self.matches as f64 / total as f64
        }
    }

    /// Whether the computation was truncated.
    #[wasm_bindgen(getter)]
    pub fn truncated(&self) -> bool {
        self.truncated
    }

    /// Error message if any.
    #[wasm_bindgen(getter)]
    pub fn error(&self) -> Option<String> {
        self.error.clone()
    }

    /// Length of sequence A.
    #[wasm_bindgen(getter)]
    pub fn len_a(&self) -> usize {
        self.mask_a.len()
    }

    /// Length of sequence B.
    #[wasm_bindgen(getter)]
    pub fn len_b(&self) -> usize {
        self.mask_b.len()
    }
}

/// Normalize a DNA base for comparison.
/// - Case-insensitive (returns uppercase code)
/// - U treated as T
/// - Returns the byte as-is for ambiguous bases (N, etc.)
#[inline(always)]
fn normalize_base(b: u8) -> u8 {
    match b {
        b'A' | b'a' => b'A',
        b'C' | b'c' => b'C',
        b'G' | b'g' => b'G',
        b'T' | b't' | b'U' | b'u' => b'T',
        other => other.to_ascii_uppercase(),
    }
}

/// Compare two normalized bases for equality.
/// N does not match anything including itself (conservative behavior).
#[inline(always)]
fn bases_equal(a: u8, b: u8) -> bool {
    let na = normalize_base(a);
    let nb = normalize_base(b);
    // N doesn't match anything
    if na == b'N' || nb == b'N' {
        return false;
    }
    na == nb
}

/// Compute Myers diff between two DNA sequences.
///
/// Uses the Myers O(ND) algorithm with bounded edit distance for safety.
/// Returns a diff result with masks for both sequences and summary statistics.
///
/// # Arguments
/// * `seq_a` - First sequence (bytes)
/// * `seq_b` - Second sequence (bytes)
///
/// # Returns
/// MyersDiffResult with masks and statistics.
///
/// # Guardrails
/// - Max sequence length: 500,000 bp
/// - Max edit distance: 10,000
/// - If exceeded, returns truncated result with partial stats
#[wasm_bindgen]
pub fn myers_diff(seq_a: &[u8], seq_b: &[u8]) -> MyersDiffResult {
    myers_diff_with_limit(seq_a, seq_b, DIFF_MAX_EDIT_DISTANCE)
}

/// Compute Myers diff with custom edit distance limit.
///
/// # Arguments
/// * `seq_a` - First sequence (bytes)
/// * `seq_b` - Second sequence (bytes)
/// * `max_d` - Maximum edit distance to compute
#[wasm_bindgen]
pub fn myers_diff_with_limit(seq_a: &[u8], seq_b: &[u8], max_d: usize) -> MyersDiffResult {
    let n = seq_a.len();
    let m = seq_b.len();

    // Check length guardrails
    if n > DIFF_MAX_LEN || m > DIFF_MAX_LEN {
        return MyersDiffResult {
            mask_a: vec![],
            mask_b: vec![],
            edit_distance: 0,
            matches: 0,
            mismatches: 0,
            insertions: 0,
            deletions: 0,
            truncated: true,
            error: Some(format!(
                "Sequence too long: len_a={}, len_b={}, max={}",
                n, m, DIFF_MAX_LEN
            )),
        };
    }

    // Empty sequence cases
    if n == 0 && m == 0 {
        return MyersDiffResult {
            mask_a: vec![],
            mask_b: vec![],
            edit_distance: 0,
            matches: 0,
            mismatches: 0,
            insertions: 0,
            deletions: 0,
            truncated: false,
            error: None,
        };
    }

    if n == 0 {
        // All insertions
        return MyersDiffResult {
            mask_a: vec![],
            mask_b: vec![DIFF_OP_INSERT; m],
            edit_distance: m,
            matches: 0,
            mismatches: 0,
            insertions: m,
            deletions: 0,
            truncated: false,
            error: None,
        };
    }

    if m == 0 {
        // All deletions
        return MyersDiffResult {
            mask_a: vec![DIFF_OP_DELETE; n],
            mask_b: vec![],
            edit_distance: n,
            matches: 0,
            mismatches: 0,
            insertions: 0,
            deletions: n,
            truncated: false,
            error: None,
        };
    }

    // Fast path: equal-length sequences - check if all match first
    if n == m {
        let mut all_match = true;
        for i in 0..n {
            if !bases_equal(seq_a[i], seq_b[i]) {
                all_match = false;
                break;
            }
        }
        if all_match {
            return MyersDiffResult {
                mask_a: vec![DIFF_OP_MATCH; n],
                mask_b: vec![DIFF_OP_MATCH; m],
                edit_distance: 0,
                matches: n,
                mismatches: 0,
                insertions: 0,
                deletions: 0,
                truncated: false,
                error: None,
            };
        }
    }

    // Run Myers algorithm
    myers_diff_core(seq_a, seq_b, max_d)
}

/// Core Myers diff algorithm implementation.
///
/// Myers O(ND) algorithm finds the shortest edit script.
/// We trace back to reconstruct the alignment.
fn myers_diff_core(seq_a: &[u8], seq_b: &[u8], max_d: usize) -> MyersDiffResult {
    let n = seq_a.len() as isize;
    let m = seq_b.len() as isize;
    let max_steps = (n + m) as usize;
    let max_d = max_d.min(max_steps);

    // V array stores furthest reaching point for each diagonal k
    // Diagonal k = x - y (where x is position in A, y is position in B)
    // We need diagonals from -(max_d) to +(max_d)
    // Array index: k + offset where offset = max_d
    let offset = max_d as isize;
    let v_size = 2 * max_d + 1;

    // Store V arrays for each d value (for traceback)
    let mut history: Vec<Vec<isize>> = Vec::with_capacity(max_d + 1);
    let mut v: Vec<isize> = vec![-1; v_size];
    v[offset as usize] = 0; // Start at (0,0)

    let mut found_d: Option<usize> = None;

    // Forward pass: find shortest edit path
    'outer: for d in 0..=max_d {
        // Save current V for traceback
        history.push(v.clone());

        for k in (-(d as isize)..=(d as isize)).step_by(2) {
            let idx = (k + offset) as usize;

            // Choose starting x based on whether we came from diagonal k-1 or k+1
            let mut x: isize;
            if d == 0 {
                // Special case: d=0 means we start at (0,0) on diagonal k=0
                x = 0;
            } else if k == -(d as isize) {
                // Must come from k+1 (insertion from B)
                x = v[(k + 1 + offset) as usize];
            } else if k == (d as isize) {
                // Must come from k-1 (deletion from A)
                x = v[(k - 1 + offset) as usize] + 1;
            } else {
                // Choose the path that goes further
                let from_above = v[(k - 1 + offset) as usize] + 1; // deletion
                let from_left = v[(k + 1 + offset) as usize];       // insertion
                x = if from_above > from_left { from_above } else { from_left };
            }

            let mut y = x - k;

            // Extend along diagonal (matches)
            // Note: y can be negative if k > x, so we must check y >= 0
            while x >= 0 && y >= 0 && x < n && y < m && bases_equal(seq_a[x as usize], seq_b[y as usize]) {
                x += 1;
                y += 1;
            }

            v[idx] = x;

            // Check if we've reached the end
            if x >= n && y >= m {
                found_d = Some(d);
                history.push(v.clone()); // Save final state
                break 'outer;
            }
        }
    }

    // Check if we found a solution
    let final_d = match found_d {
        Some(d) => d,
        None => {
            // Edit distance exceeded limit
            return MyersDiffResult {
                mask_a: vec![],
                mask_b: vec![],
                edit_distance: 0,
                matches: 0,
                mismatches: 0,
                insertions: 0,
                deletions: 0,
                truncated: true,
                error: Some(format!(
                    "Edit distance exceeds limit: max_d={}",
                    max_d
                )),
            };
        }
    };

    // Traceback to reconstruct alignment
    // Build edit script in reverse, then reverse at the end
    let mut edits: Vec<(u8, usize, usize)> = Vec::new(); // (op, pos_a, pos_b)

    let mut x = n as usize;
    let mut y = m as usize;
    let mut d = final_d;

    while x > 0 || y > 0 {
        if d == 0 {
            // Only matches remain
            while x > 0 && y > 0 {
                x -= 1;
                y -= 1;
                edits.push((DIFF_OP_MATCH, x, y));
            }
            break;
        }

        let k = x as isize - y as isize;
        // history[d] contains V after iteration d-1 completed (pushed at start of d)
        let v_prev = &history[d];

        // Determine if we came from k-1 (deletion) or k+1 (insertion)
        let k_prev_del = k - 1;
        let k_prev_ins = k + 1;

        let from_del = if ((k_prev_del + offset) as usize) < v_prev.len() {
            v_prev[(k_prev_del + offset) as usize]
        } else {
            -2
        };
        let from_ins = if ((k_prev_ins + offset) as usize) < v_prev.len() {
            v_prev[(k_prev_ins + offset) as usize]
        } else {
            -2
        };

        // Compute snake start point
        let snake_start_x: usize;
        let is_deletion: bool;

        if k == -(d as isize) {
            // Must be insertion
            snake_start_x = from_ins as usize;
            is_deletion = false;
        } else if k == (d as isize) {
            // Must be deletion
            snake_start_x = (from_del + 1) as usize;
            is_deletion = true;
        } else if from_del + 1 > from_ins {
            // Deletion gives better path
            snake_start_x = (from_del + 1) as usize;
            is_deletion = true;
        } else {
            // Insertion gives better path
            snake_start_x = from_ins as usize;
            is_deletion = false;
        }

        let snake_start_y = (snake_start_x as isize - k) as usize;

        // Trace matches in the snake
        while x > snake_start_x && y > snake_start_y {
            x -= 1;
            y -= 1;
            edits.push((DIFF_OP_MATCH, x, y));
        }

        // The edit step
        if is_deletion {
            if x > 0 {
                x -= 1;
                edits.push((DIFF_OP_DELETE, x, y));
            }
        } else {
            if y > 0 {
                y -= 1;
                edits.push((DIFF_OP_INSERT, x, y));
            }
        }

        d -= 1;
    }

    // Reverse to get forward order
    edits.reverse();

    // Build masks from edits
    let mut mask_a = vec![DIFF_OP_MATCH; seq_a.len()];
    let mut mask_b = vec![DIFF_OP_MATCH; seq_b.len()];
    let mut matches = 0usize;
    let mismatches = 0usize; // Myers algorithm doesn't produce substitutions, only ins/del
    let mut insertions = 0usize;
    let mut deletions = 0usize;

    for (op, pos_a, pos_b) in edits {
        match op {
            DIFF_OP_MATCH => {
                if pos_a < mask_a.len() {
                    mask_a[pos_a] = DIFF_OP_MATCH;
                }
                if pos_b < mask_b.len() {
                    mask_b[pos_b] = DIFF_OP_MATCH;
                }
                matches += 1;
            }
            DIFF_OP_DELETE => {
                if pos_a < mask_a.len() {
                    mask_a[pos_a] = DIFF_OP_DELETE;
                }
                deletions += 1;
            }
            DIFF_OP_INSERT => {
                if pos_b < mask_b.len() {
                    mask_b[pos_b] = DIFF_OP_INSERT;
                }
                insertions += 1;
            }
            _ => {}
        }
    }

    MyersDiffResult {
        mask_a,
        mask_b,
        edit_distance: final_d,
        matches,
        mismatches,
        insertions,
        deletions,
        truncated: false,
        error: None,
    }
}

/// Fast equal-length diff for sequences with only substitutions.
///
/// This is O(n) and much faster than Myers when we know there are no indels.
/// Use this when sequences are already aligned or have equal length.
///
/// # Arguments
/// * `seq_a` - First sequence (bytes)
/// * `seq_b` - Second sequence (bytes)
///
/// # Returns
/// MyersDiffResult with mask codes 0=MATCH, 1=MISMATCH only.
#[wasm_bindgen]
pub fn equal_len_diff(seq_a: &[u8], seq_b: &[u8]) -> MyersDiffResult {
    let n = seq_a.len();
    let m = seq_b.len();

    if n != m {
        return MyersDiffResult {
            mask_a: vec![],
            mask_b: vec![],
            edit_distance: 0,
            matches: 0,
            mismatches: 0,
            insertions: 0,
            deletions: 0,
            truncated: true,
            error: Some(format!(
                "Sequences must have equal length for equal_len_diff: {} vs {}",
                n, m
            )),
        };
    }

    let mut mask = Vec::with_capacity(n);
    let mut matches = 0usize;
    let mut mismatches = 0usize;

    for i in 0..n {
        if bases_equal(seq_a[i], seq_b[i]) {
            mask.push(DIFF_OP_MATCH);
            matches += 1;
        } else {
            mask.push(DIFF_OP_MISMATCH);
            mismatches += 1;
        }
    }

    MyersDiffResult {
        mask_a: mask.clone(),
        mask_b: mask,
        edit_distance: mismatches,
        matches,
        mismatches,
        insertions: 0,
        deletions: 0,
        truncated: false,
        error: None,
    }
}

// ============================================================================
// SequenceHandle: Zero-copy sequence storage in WASM memory
// ============================================================================

/// Encoding for DNA bases in SequenceHandle.
/// A=0, C=1, G=2, T/U=3, N/other=4
const SEQ_BASE_A: u8 = 0;
const SEQ_BASE_C: u8 = 1;
const SEQ_BASE_G: u8 = 2;
const SEQ_BASE_T: u8 = 3;
const SEQ_BASE_N: u8 = 4;

/// Encode a single ASCII base to 2-bit encoding (A=0, C=1, G=2, T=3, N=4).
#[inline(always)]
fn encode_base(byte: u8) -> u8 {
    match byte {
        b'A' | b'a' => SEQ_BASE_A,
        b'C' | b'c' => SEQ_BASE_C,
        b'G' | b'g' => SEQ_BASE_G,
        b'T' | b't' | b'U' | b'u' => SEQ_BASE_T,
        _ => SEQ_BASE_N,
    }
}

/// A handle to a sequence stored in WASM memory.
///
/// This struct stores an encoded DNA sequence once and exposes fast methods
/// for various analyses without re-copying the sequence each call.
///
/// # Usage
///
/// ```js
/// const handle = SequenceHandle.new(sequenceBytes);
/// try {
///   const gcSkew = handle.gc_skew(100, 10);
///   const kmerCounts = handle.count_kmers(4);
///   // ... use results
/// } finally {
///   handle.free(); // MUST call to release WASM memory
/// }
/// ```
///
/// # Memory Management
///
/// The caller MUST call `.free()` when done to release WASM memory.
/// Failing to do so will leak memory.
///
/// @see phage_explorer-8qk2.5
#[wasm_bindgen]
pub struct SequenceHandle {
    /// Encoded sequence: A=0, C=1, G=2, T=3, N=4
    encoded: Vec<u8>,
    /// Original sequence length
    length: usize,
    /// Count of valid (non-N) bases
    valid_count: usize,
}

#[wasm_bindgen]
impl SequenceHandle {
    /// Create a new SequenceHandle from raw sequence bytes.
    ///
    /// The sequence is encoded into a compact representation stored in WASM memory.
    /// Case-insensitive: a/A, c/C, g/G, t/T are all valid.
    /// U is treated as T. Ambiguous/invalid bases are stored as N (code 4).
    ///
    /// # Arguments
    /// * `seq_bytes` - ASCII bytes of the DNA/RNA sequence
    ///
    /// # Returns
    /// A new SequenceHandle that must be freed with `.free()` when done.
    #[wasm_bindgen(constructor)]
    pub fn new(seq_bytes: &[u8]) -> SequenceHandle {
        let length = seq_bytes.len();
        let mut encoded = Vec::with_capacity(length);
        let mut valid_count = 0;

        for &byte in seq_bytes {
            let code = encode_base(byte);
            encoded.push(code);
            if code != SEQ_BASE_N {
                valid_count += 1;
            }
        }

        SequenceHandle {
            encoded,
            length,
            valid_count,
        }
    }

    /// Get the original sequence length.
    #[wasm_bindgen(getter)]
    pub fn length(&self) -> usize {
        self.length
    }

    /// Get the count of valid (non-N) bases.
    #[wasm_bindgen(getter)]
    pub fn valid_count(&self) -> usize {
        self.valid_count
    }

    /// Compute GC skew values for sliding windows.
    ///
    /// GC skew = (G - C) / (G + C) for each window.
    /// Returns an empty array if window_size or step_size is 0, or if
    /// the sequence is shorter than window_size.
    ///
    /// # Arguments
    /// * `window_size` - Size of the sliding window
    /// * `step_size` - Step between windows
    ///
    /// # Returns
    /// Float64Array of GC skew values, one per window position.
    pub fn gc_skew(&self, window_size: usize, step_size: usize) -> Vec<f64> {
        if window_size == 0 || step_size == 0 || self.length < window_size {
            return Vec::new();
        }

        let mut result = Vec::with_capacity((self.length - window_size) / step_size + 1);

        // Initial window counts
        let mut g_count = 0usize;
        let mut c_count = 0usize;

        for i in 0..window_size {
            match self.encoded[i] {
                SEQ_BASE_G => g_count += 1,
                SEQ_BASE_C => c_count += 1,
                _ => {}
            }
        }

        // First window
        let gc_sum = g_count + c_count;
        if gc_sum > 0 {
            result.push((g_count as f64 - c_count as f64) / gc_sum as f64);
        } else {
            result.push(0.0);
        }

        // Slide the window
        let mut pos = step_size;
        while pos + window_size <= self.length {
            // Remove bases exiting the window
            for i in (pos - step_size)..pos {
                if i < self.length {
                    match self.encoded[i] {
                        SEQ_BASE_G => g_count = g_count.saturating_sub(1),
                        SEQ_BASE_C => c_count = c_count.saturating_sub(1),
                        _ => {}
                    }
                }
            }
            // Add bases entering the window
            for i in (pos + window_size - step_size)..(pos + window_size) {
                if i < self.length {
                    match self.encoded[i] {
                        SEQ_BASE_G => g_count += 1,
                        SEQ_BASE_C => c_count += 1,
                        _ => {}
                    }
                }
            }

            let gc_sum = g_count + c_count;
            if gc_sum > 0 {
                result.push((g_count as f64 - c_count as f64) / gc_sum as f64);
            } else {
                result.push(0.0);
            }

            pos += step_size;
        }

        result
    }

    /// Compute cumulative GC skew.
    ///
    /// Running sum of (G - C) / (G + C) contribution per base.
    /// The cumulative skew typically shows the origin (minimum) and terminus (maximum)
    /// of replication for circular genomes.
    ///
    /// # Returns
    /// Float64Array with cumulative skew at each position.
    pub fn cumulative_gc_skew(&self) -> Vec<f64> {
        let mut cumulative = Vec::with_capacity(self.length);
        let mut sum = 0.0;

        for &code in &self.encoded {
            match code {
                SEQ_BASE_G => sum += 1.0,
                SEQ_BASE_C => sum -= 1.0,
                _ => {}
            }
            cumulative.push(sum);
        }

        cumulative
    }

    /// Count k-mers using dense array (for k <= 10).
    ///
    /// Returns a DenseKmerResult with counts for all 4^k possible k-mers.
    /// K-mers containing N are skipped.
    ///
    /// # Arguments
    /// * `k` - K-mer size (1-10)
    ///
    /// # Returns
    /// DenseKmerResult with counts, or empty result if k is invalid.
    pub fn count_kmers(&self, k: usize) -> DenseKmerResult {
        if k < 1 || k > DENSE_KMER_MAX_K || self.length < k {
            return DenseKmerResult {
                counts: Vec::new(),
                total_valid: 0,
                k,
            };
        }

        let array_size = 1 << (2 * k);
        let mask = array_size - 1;
        let mut counts = vec![0u32; array_size];
        let mut total_valid = 0u64;

        let mut rolling_index = 0usize;
        let mut valid_bases = 0usize;

        for &code in &self.encoded {
            if code == SEQ_BASE_N {
                // Reset on N
                rolling_index = 0;
                valid_bases = 0;
                continue;
            }

            rolling_index = ((rolling_index << 2) | (code as usize)) & mask;
            valid_bases += 1;

            if valid_bases >= k {
                counts[rolling_index] = counts[rolling_index].saturating_add(1);
                total_valid += 1;
            }
        }

        DenseKmerResult {
            counts,
            total_valid,
            k,
        }
    }

    /// Compute MinHash signature for similarity estimation.
    ///
    /// Uses canonical k-mers (lexicographically smaller of forward/reverse complement)
    /// for strand-independent comparison.
    ///
    /// # Arguments
    /// * `num_hashes` - Number of hash functions (signature size)
    /// * `k` - K-mer size
    ///
    /// # Returns
    /// MinHashSignature containing the signature.
    pub fn minhash(&self, num_hashes: usize, k: usize) -> MinHashSignature {
        if k < 1 || k > 31 || self.length < k || num_hashes == 0 {
            return MinHashSignature {
                signature: vec![u32::MAX; num_hashes],
                total_kmers: 0,
                k,
            };
        }

        // Convert encoded back to ASCII for canonical k-mer computation
        // (Could optimize later with direct encoding)
        let mut ascii = Vec::with_capacity(self.length);
        for &code in &self.encoded {
            ascii.push(match code {
                SEQ_BASE_A => b'A',
                SEQ_BASE_C => b'C',
                SEQ_BASE_G => b'G',
                SEQ_BASE_T => b'T',
                _ => b'N',
            });
        }

        // Use existing canonical minhash implementation
        minhash_signature_canonical(&ascii, k, num_hashes)
    }

    /// Compute self-similarity dot plot using pre-encoded sequence.
    ///
    /// This is more efficient than `dotplot_self_buffers` when running multiple
    /// analyses on the same sequence (e.g., progressive refinement with preview
    /// then full resolution).
    ///
    /// # Arguments
    /// * `bins` - Number of bins for the grid (bins Ã bins output)
    /// * `window` - Window size in bases. If 0, derives a conservative default.
    ///
    /// # Returns
    /// DotPlotBuffers containing direct and inverted similarity matrices.
    ///
    /// @see phage_explorer-8qk2.6
    pub fn dotplot_self(&self, bins: usize, window: usize) -> DotPlotBuffers {
        if self.length == 0 || bins == 0 {
            return DotPlotBuffers {
                direct: Vec::new(),
                inverted: Vec::new(),
                bins: 0,
                window: 0,
            };
        }

        let len = self.length;

        // Match JS default: max(20, floor(len/bins) || len), clamped to [1, len].
        let derived_window = {
            let base = if bins > 0 { len / bins } else { len };
            let base = if base == 0 { len } else { base };
            std::cmp::max(20usize, base)
        };
        let window = if window == 0 { derived_window } else { window };
        let window = std::cmp::max(1usize, std::cmp::min(len, window));

        // Precompute starts[] exactly like JS: floor(i * step) where step is float.
        let mut starts: Vec<usize> = vec![0; bins];
        if bins > 1 {
            let span = (len - window) as f64;
            let step = span / (bins as f64 - 1.0);
            for i in 0..bins {
                let s = ((i as f64) * step).floor() as usize;
                starts[i] = std::cmp::min(s, len - window);
            }
        } else if bins == 1 {
            starts[0] = 0;
        }

        let n = bins * bins;
        let mut direct = vec![0.0f32; n];
        let mut inverted = vec![0.0f32; n];
        let denom = window as f32;

        // Helper: complement for encoded bases (A=0âT=3, C=1âG=2, N=4 stays 4)
        #[inline(always)]
        fn complement_encoded(code: u8) -> u8 {
            if code <= 3 {
                3 - code
            } else {
                code // N stays N
            }
        }

        for i in 0..bins {
            let a0 = starts[i];

            for j in i..bins {
                let b0 = starts[j];

                let mut same_dir: u32 = 0;
                let mut same_inv: u32 = 0;

                // Direct: compare aligned window positions.
                // Inverted: compare reverse-complement of A window against B.
                for k in 0..window {
                    let a = self.encoded[a0 + k];
                    let b = self.encoded[b0 + k];

                    // Only count matches for valid bases (not N)
                    if a <= 3 && a == b {
                        same_dir += 1;
                    }

                    let a_rc = complement_encoded(self.encoded[a0 + (window - 1 - k)]);
                    if a_rc <= 3 && a_rc == b {
                        same_inv += 1;
                    }
                }

                let dir_val = (same_dir as f32) / denom;
                let inv_val = (same_inv as f32) / denom;

                let idx1 = i * bins + j;
                direct[idx1] = dir_val;
                inverted[idx1] = inv_val;

                if i != j {
                    let idx2 = j * bins + i;
                    direct[idx2] = dir_val;
                    inverted[idx2] = inv_val;
                }
            }
        }

        DotPlotBuffers {
            direct,
            inverted,
            bins,
            window,
        }
    }

    /// Get the encoded sequence as a Uint8Array.
    ///
    /// Values: A=0, C=1, G=2, T=3, N=4
    ///
    /// This is useful for passing to other WASM functions or for debugging.
    #[wasm_bindgen(getter)]
    pub fn encoded_bytes(&self) -> js_sys::Uint8Array {
        let arr = js_sys::Uint8Array::new_with_length(self.encoded.len() as u32);
        arr.copy_from(&self.encoded);
        arr
    }
}

// ============================================================================
// PDB Parser - Minimal prototype for structure parsing
// ============================================================================

/// Result of PDB parsing containing atom data.
///
/// Returns flat arrays suitable for direct use with detect_bonds_spatial.
/// This parser is intentionally minimal (no external crates) to keep WASM size small.
#[wasm_bindgen]
pub struct PDBParseResult {
    /// Flat positions array [x0, y0, z0, x1, y1, z1, ...]
    positions: Vec<f32>,
    /// Element symbols as single chars "CCCCNNO..."
    elements: String,
    /// Atom names (4 chars each, space-padded) "CA  CB  N   O   ..."
    atom_names: String,
    /// Chain IDs as single chars "AAABBBB..."
    chain_ids: String,
    /// Residue sequence numbers
    res_seqs: Vec<i32>,
    /// Residue names (3 chars each) "ALAGLYVAL..."
    res_names: String,
    /// Number of atoms parsed
    atom_count: usize,
    /// Parse errors or warnings (empty if clean)
    error: String,
}

#[wasm_bindgen]
impl PDBParseResult {
    #[wasm_bindgen(getter)]
    pub fn positions(&self) -> js_sys::Float32Array {
        let arr = js_sys::Float32Array::new_with_length(self.positions.len() as u32);
        arr.copy_from(&self.positions);
        arr
    }

    #[wasm_bindgen(getter)]
    pub fn elements(&self) -> String {
        self.elements.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn atom_names(&self) -> String {
        self.atom_names.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn chain_ids(&self) -> String {
        self.chain_ids.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn res_seqs(&self) -> js_sys::Int32Array {
        let arr = js_sys::Int32Array::new_with_length(self.res_seqs.len() as u32);
        arr.copy_from(&self.res_seqs);
        arr
    }

    #[wasm_bindgen(getter)]
    pub fn res_names(&self) -> String {
        self.res_names.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn atom_count(&self) -> usize {
        self.atom_count
    }

    #[wasm_bindgen(getter)]
    pub fn error(&self) -> String {
        self.error.clone()
    }
}

/// Parse a PDB file (string content) into atom data.
///
/// This is a minimal parser optimized for speed and small WASM size.
/// It extracts only the fields needed for 3D structure visualization:
/// - Coordinates (x, y, z)
/// - Element symbol
/// - Atom name
/// - Chain ID
/// - Residue sequence number
/// - Residue name
///
/// # Arguments
/// * `pdb_content` - Raw PDB file content as string
///
/// # Returns
/// PDBParseResult with flat arrays ready for bond detection and rendering.
///
/// # PDB Format Reference (fixed columns):
/// - Columns 1-6: Record type ("ATOM  " or "HETATM")
/// - Columns 13-16: Atom name
/// - Column 18-20: Residue name
/// - Column 22: Chain ID
/// - Columns 23-26: Residue sequence number
/// - Columns 31-38: X coordinate (Angstroms)
/// - Columns 39-46: Y coordinate
/// - Columns 47-54: Z coordinate
/// - Columns 77-78: Element symbol (right-justified)
#[wasm_bindgen]
pub fn parse_pdb(pdb_content: &str) -> PDBParseResult {
    let mut positions: Vec<f32> = Vec::new();
    let mut elements = String::new();
    let mut atom_names = String::new();
    let mut chain_ids = String::new();
    let mut res_seqs: Vec<i32> = Vec::new();
    let mut res_names = String::new();
    let error = String::new();

    for line in pdb_content.lines() {
        let bytes = line.as_bytes();

        // Check for ATOM or HETATM records
        if bytes.len() < 54 {
            continue;
        }

        let record_type = if bytes.len() >= 6 { &line[0..6] } else { continue };
        if record_type != "ATOM  " && record_type != "HETATM" {
            continue;
        }

        // Parse coordinates (columns 31-38, 39-46, 47-54, 1-indexed, 0-indexed: 30-38, 38-46, 46-54)
        let x = parse_float(&line, 30, 38);
        let y = parse_float(&line, 38, 46);
        let z = parse_float(&line, 46, 54);

        // Skip atoms with invalid coordinates
        let (x, y, z) = match (x, y, z) {
            (Some(x), Some(y), Some(z)) => (x, y, z),
            _ => continue,
        };

        positions.push(x);
        positions.push(y);
        positions.push(z);

        // Atom name (columns 13-16, 0-indexed: 12-16)
        let atom_name = if bytes.len() >= 16 {
            &line[12..16]
        } else {
            "    "
        };
        atom_names.push_str(atom_name);

        // Residue name (columns 18-20, 0-indexed: 17-20)
        let res_name = if bytes.len() >= 20 {
            &line[17..20]
        } else {
            "   "
        };
        res_names.push_str(res_name);

        // Chain ID (column 22, 0-indexed: 21)
        let chain_id = if bytes.len() >= 22 {
            bytes[21] as char
        } else {
            ' '
        };
        chain_ids.push(chain_id);

        // Residue sequence number (columns 23-26, 0-indexed: 22-26)
        let res_seq = if bytes.len() >= 26 {
            line[22..26].trim().parse::<i32>().unwrap_or(0)
        } else {
            0
        };
        res_seqs.push(res_seq);

        // Element symbol (columns 77-78, 0-indexed: 76-78)
        // If not available, derive from atom name
        let element = if bytes.len() >= 78 {
            let elem_str = line[76..78].trim();
            if elem_str.is_empty() {
                derive_element_from_atom_name(atom_name)
            } else {
                elem_str.chars().next().unwrap_or('C')
            }
        } else {
            derive_element_from_atom_name(atom_name)
        };
        elements.push(element);
    }

    let atom_count = elements.len();

    PDBParseResult {
        positions,
        elements,
        atom_names,
        chain_ids,
        res_seqs,
        res_names,
        atom_count,
        error,
    }
}

/// Helper: parse a float from a fixed-width PDB column
fn parse_float(line: &str, start: usize, end: usize) -> Option<f32> {
    if line.len() < end {
        return None;
    }
    line[start..end].trim().parse::<f32>().ok()
}

/// Helper: derive element from atom name (fallback when element column missing)
fn derive_element_from_atom_name(atom_name: &str) -> char {
    let name = atom_name.trim();
    if name.is_empty() {
        return 'C';
    }

    // First non-digit character is usually the element
    for c in name.chars() {
        match c {
            'C' | 'N' | 'O' | 'S' | 'P' | 'H' | 'F' => return c,
            _ => continue,
        }
    }

    // Default to carbon if we can't determine
    'C'
}

#[cfg(test)]
mod pdb_parser_tests {
    use super::*;

    #[test]
    fn test_parse_simple_atom() {
        let pdb = "ATOM      1  CA  ALA A   1       1.000   2.000   3.000  1.00  0.00           C";
        let result = parse_pdb(pdb);

        assert_eq!(result.atom_count, 1);
        assert_eq!(result.positions.len(), 3);
        assert!((result.positions[0] - 1.0).abs() < 0.001);
        assert!((result.positions[1] - 2.0).abs() < 0.001);
        assert!((result.positions[2] - 3.0).abs() < 0.001);
        assert_eq!(result.elements, "C");
        assert_eq!(result.chain_ids, "A");
    }

    #[test]
    fn test_parse_hetatm() {
        let pdb = "HETATM    1  O   HOH A   1       0.000   0.000   0.000  1.00  0.00           O";
        let result = parse_pdb(pdb);

        assert_eq!(result.atom_count, 1);
        assert_eq!(result.elements, "O");
    }

    #[test]
    fn test_skip_invalid_lines() {
        let pdb = "HEADER some header\nATOM      1  CA  ALA A   1       1.000   2.000   3.000  1.00  0.00           C\nREMARK 100 some remark";
        let result = parse_pdb(pdb);

        assert_eq!(result.atom_count, 1);
    }

    #[test]
    fn test_element_derivation() {
        assert_eq!(derive_element_from_atom_name(" CA "), 'C');
        assert_eq!(derive_element_from_atom_name(" N  "), 'N');
        assert_eq!(derive_element_from_atom_name(" O  "), 'O');
        assert_eq!(derive_element_from_atom_name("1HG2"), 'H');
    }
}

#[cfg(test)]
mod sequence_handle_tests {
    use super::*;

    #[test]
    fn test_new_and_length() {
        let handle = SequenceHandle::new(b"ACGT");
        assert_eq!(handle.length, 4);
        assert_eq!(handle.valid_count, 4);
    }

    #[test]
    fn test_encoding() {
        let handle = SequenceHandle::new(b"ACGTacgt");
        // All should be valid (case-insensitive)
        assert_eq!(handle.valid_count, 8);
        assert_eq!(handle.encoded[0], SEQ_BASE_A);
        assert_eq!(handle.encoded[1], SEQ_BASE_C);
        assert_eq!(handle.encoded[2], SEQ_BASE_G);
        assert_eq!(handle.encoded[3], SEQ_BASE_T);
    }

    #[test]
    fn test_n_handling() {
        let handle = SequenceHandle::new(b"ACNGT");
        assert_eq!(handle.length, 5);
        assert_eq!(handle.valid_count, 4);
        assert_eq!(handle.encoded[2], SEQ_BASE_N);
    }

    #[test]
    fn test_gc_skew_basic() {
        // GGGG has skew 1.0, CCCC has skew -1.0
        let handle = SequenceHandle::new(b"GGGGCCCC");
        let skew = handle.gc_skew(4, 4);
        assert_eq!(skew.len(), 2);
        assert!((skew[0] - 1.0).abs() < 0.001);
        assert!((skew[1] - (-1.0)).abs() < 0.001);
    }

    #[test]
    fn test_cumulative_gc_skew() {
        let handle = SequenceHandle::new(b"GGCC");
        let cum = handle.cumulative_gc_skew();
        assert_eq!(cum.len(), 4);
        assert_eq!(cum[0], 1.0); // G
        assert_eq!(cum[1], 2.0); // G
        assert_eq!(cum[2], 1.0); // C
        assert_eq!(cum[3], 0.0); // C
    }

    #[test]
    fn test_count_kmers() {
        let handle = SequenceHandle::new(b"ACGT");
        let result = handle.count_kmers(2);
        assert_eq!(result.total_valid, 3); // AC, CG, GT
        assert_eq!(result.k, 2);
    }

    #[test]
    fn test_count_kmers_with_n() {
        let handle = SequenceHandle::new(b"ACNGT");
        let result = handle.count_kmers(2);
        // AC, then N breaks, then GT
        assert_eq!(result.total_valid, 2);
    }

    #[test]
    fn test_minhash() {
        let handle = SequenceHandle::new(b"ACGTACGTACGT");
        let sig = handle.minhash(128, 3);
        assert_eq!(sig.signature.len(), 128);
        assert_eq!(sig.k, 3);
        // Signature should have some actual values (not all MAX)
        assert!(sig.signature.iter().any(|&v| v != u32::MAX));
    }

    #[test]
    fn test_dotplot_self_basic() {
        // Same test case as dotplot_self_buffers test
        let handle = SequenceHandle::new(b"ACGT");
        let result = handle.dotplot_self(2, 2);

        assert_eq!(result.bins, 2);
        assert_eq!(result.window, 2);
        assert_eq!(result.direct.len(), 4);
        assert_eq!(result.inverted.len(), 4);

        // Diagonal should be 1.0 (self-similarity)
        assert!((result.direct[0] - 1.0).abs() < 1e-6);
        assert!((result.direct[3] - 1.0).abs() < 1e-6);
    }

    #[test]
    fn test_dotplot_self_parity_with_buffers() {
        // Verify SequenceHandle.dotplot_self matches dotplot_self_buffers
        let seq = b"ACGTACGTACGTACGTACGTACGTACGT";
        let handle = SequenceHandle::new(seq);

        let handle_result = handle.dotplot_self(4, 5);
        let buffers_result = dotplot_self_buffers(seq, 4, 5);

        assert_eq!(handle_result.bins, buffers_result.bins);
        assert_eq!(handle_result.window, buffers_result.window);

        for i in 0..handle_result.direct.len() {
            assert!(
                (handle_result.direct[i] - buffers_result.direct[i]).abs() < 1e-6,
                "direct[{}]: {} vs {}",
                i,
                handle_result.direct[i],
                buffers_result.direct[i]
            );
            assert!(
                (handle_result.inverted[i] - buffers_result.inverted[i]).abs() < 1e-6,
                "inverted[{}]: {} vs {}",
                i,
                handle_result.inverted[i],
                buffers_result.inverted[i]
            );
        }
    }
}

#[cfg(test)]
mod myers_diff_tests {
    use super::*;

    #[test]
    fn test_identical_sequences() {
        let result = myers_diff(b"ACGT", b"ACGT");
        assert_eq!(result.edit_distance, 0);
        assert_eq!(result.matches, 4);
        assert_eq!(result.insertions, 0);
        assert_eq!(result.deletions, 0);
        assert!(!result.truncated);
        assert!(result.error.is_none());
        assert_eq!(result.mask_a.len(), 4);
        assert_eq!(result.mask_b.len(), 4);
    }

    #[test]
    fn test_empty_sequences() {
        let result = myers_diff(b"", b"");
        assert_eq!(result.edit_distance, 0);
        assert_eq!(result.matches, 0);
        assert!(!result.truncated);
    }

    #[test]
    fn test_insertion() {
        // B has extra base
        let result = myers_diff(b"ACGT", b"ACGGT");
        assert_eq!(result.edit_distance, 1);
        assert_eq!(result.insertions, 1);
        assert_eq!(result.deletions, 0);
        assert_eq!(result.matches, 4);
    }

    #[test]
    fn test_deletion() {
        // A has extra base
        let result = myers_diff(b"ACGGT", b"ACGT");
        assert_eq!(result.edit_distance, 1);
        assert_eq!(result.deletions, 1);
        assert_eq!(result.insertions, 0);
        assert_eq!(result.matches, 4);
    }

    #[test]
    fn test_case_insensitive() {
        let result = myers_diff(b"acgt", b"ACGT");
        assert_eq!(result.edit_distance, 0);
        assert_eq!(result.matches, 4);
    }

    #[test]
    fn test_u_treated_as_t() {
        let result = myers_diff(b"ACGU", b"ACGT");
        assert_eq!(result.edit_distance, 0);
        assert_eq!(result.matches, 4);
    }

    #[test]
    fn test_n_never_matches() {
        // N doesn't match anything, not even N
        let result = myers_diff(b"ANCGT", b"ATCGT");
        // N vs T is a mismatch, handled as edit
        assert!(result.edit_distance > 0);
    }

    #[test]
    fn test_equal_len_diff_identical() {
        let result = equal_len_diff(b"ACGT", b"ACGT");
        assert_eq!(result.edit_distance, 0);
        assert_eq!(result.matches, 4);
        assert_eq!(result.mismatches, 0);
    }

    #[test]
    fn test_equal_len_diff_with_mismatches() {
        let result = equal_len_diff(b"ACGT", b"ACCT");
        assert_eq!(result.edit_distance, 1);
        assert_eq!(result.matches, 3);
        assert_eq!(result.mismatches, 1);
    }

    #[test]
    fn test_equal_len_diff_different_lengths() {
        let result = equal_len_diff(b"ACGT", b"ACG");
        assert!(result.truncated);
        assert!(result.error.is_some());
    }

    #[test]
    fn test_guardrails_max_edit_distance() {
        // Create sequences with high edit distance
        let a = vec![b'A'; 100];
        let b = vec![b'G'; 100];
        let result = myers_diff_with_limit(&a, &b, 10);
        // Should truncate since edit distance is 100 but limit is 10
        assert!(result.truncated);
    }

    #[test]
    fn test_insertion_mask_positions() {
        // A = "ACGT", B = "ACGGT" (extra G in B at position 3)
        // Correct alignment:
        //   A: ACG-T
        //   B: ACGGT
        // So B[3]=G is the inserted base
        let result = myers_diff(b"ACGT", b"ACGGT");
        assert_eq!(result.edit_distance, 1);
        assert_eq!(result.insertions, 1);
        assert_eq!(result.matches, 4);

        // Check mask_a: all should be MATCH
        assert_eq!(result.mask_a.len(), 4);
        for i in 0..4 {
            assert_eq!(result.mask_a[i], DIFF_OP_MATCH, "mask_a[{}] should be MATCH", i);
        }

        // Check mask_b: position 3 should be INSERT, others MATCH
        assert_eq!(result.mask_b.len(), 5);
        assert_eq!(result.mask_b[0], DIFF_OP_MATCH, "mask_b[0] should be MATCH");
        assert_eq!(result.mask_b[1], DIFF_OP_MATCH, "mask_b[1] should be MATCH");
        assert_eq!(result.mask_b[2], DIFF_OP_MATCH, "mask_b[2] should be MATCH");
        assert_eq!(result.mask_b[3], DIFF_OP_INSERT, "mask_b[3] should be INSERT");
        assert_eq!(result.mask_b[4], DIFF_OP_MATCH, "mask_b[4] should be MATCH");
    }

    #[test]
    fn test_deletion_mask_positions() {
        // A = "ACGGT", B = "ACGT" (extra G in A at position 3)
        // Correct alignment:
        //   A: ACGGT
        //   B: ACG-T
        // So A[3]=G is the deleted base
        let result = myers_diff(b"ACGGT", b"ACGT");
        assert_eq!(result.edit_distance, 1);
        assert_eq!(result.deletions, 1);
        assert_eq!(result.matches, 4);

        // Check mask_a: position 3 should be DELETE, others MATCH
        assert_eq!(result.mask_a.len(), 5);
        assert_eq!(result.mask_a[0], DIFF_OP_MATCH, "mask_a[0] should be MATCH");
        assert_eq!(result.mask_a[1], DIFF_OP_MATCH, "mask_a[1] should be MATCH");
        assert_eq!(result.mask_a[2], DIFF_OP_MATCH, "mask_a[2] should be MATCH");
        assert_eq!(result.mask_a[3], DIFF_OP_DELETE, "mask_a[3] should be DELETE");
        assert_eq!(result.mask_a[4], DIFF_OP_MATCH, "mask_a[4] should be MATCH");

        // Check mask_b: all should be MATCH
        assert_eq!(result.mask_b.len(), 4);
        for i in 0..4 {
            assert_eq!(result.mask_b[i], DIFF_OP_MATCH, "mask_b[{}] should be MATCH", i);
        }
    }

    #[test]
    fn test_single_char_sequences() {
        // Same single char
        let result = myers_diff(b"A", b"A");
        assert_eq!(result.edit_distance, 0);
        assert_eq!(result.matches, 1);
        assert_eq!(result.mask_a, vec![DIFF_OP_MATCH]);
        assert_eq!(result.mask_b, vec![DIFF_OP_MATCH]);

        // Different single chars
        let result = myers_diff(b"A", b"G");
        assert_eq!(result.edit_distance, 2); // 1 delete + 1 insert
        assert_eq!(result.deletions, 1);
        assert_eq!(result.insertions, 1);
        assert_eq!(result.matches, 0);
    }

    #[test]
    fn test_one_empty_one_nonempty() {
        // A empty, B has content
        let result = myers_diff(b"", b"ACGT");
        assert_eq!(result.edit_distance, 4);
        assert_eq!(result.insertions, 4);
        assert_eq!(result.mask_a.len(), 0);
        assert_eq!(result.mask_b.len(), 4);
        for i in 0..4 {
            assert_eq!(result.mask_b[i], DIFF_OP_INSERT);
        }

        // A has content, B empty
        let result = myers_diff(b"ACGT", b"");
        assert_eq!(result.edit_distance, 4);
        assert_eq!(result.deletions, 4);
        assert_eq!(result.mask_a.len(), 4);
        assert_eq!(result.mask_b.len(), 0);
        for i in 0..4 {
            assert_eq!(result.mask_a[i], DIFF_OP_DELETE);
        }
    }

    #[test]
    fn test_multiple_edits() {
        // A = "ACGT", B = "AXXGT" (delete C, insert XX)
        // This tests multiple edits in one diff
        let result = myers_diff(b"ACGT", b"AXXGT");
        // edit_distance should be 3: delete C, insert X, insert X
        assert_eq!(result.edit_distance, 3);
        // Total positions: matches (A, G, T = 3) + deletions (C = 1) + insertions (X, X = 2) = 6
        // But wait, that's not how it works. Let me recalculate.
        // Actually the shortest edit script would be:
        // Keep A, delete C, insert X, insert X, keep G, keep T
        // = 1 deletion + 2 insertions = 3 edits, 3 matches
        assert_eq!(result.matches, 3);
        assert!(result.insertions + result.deletions == 3);
    }

    #[test]
    fn test_prefix_suffix_matches() {
        // Only differ in the middle
        let result = myers_diff(b"AAAXBBB", b"AAAYBBB");
        // X and Y differ: delete X, insert Y = 2 edits
        assert_eq!(result.edit_distance, 2);
        assert_eq!(result.matches, 6); // AAA + BBB
    }
}
